{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "import numpy as np\n",
    "import ast\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_columns = ['belongs_to_collection', 'genres', 'production_companies',\n",
    "                'production_countries', 'spoken_languages', 'Keywords',\n",
    "                'cast', 'crew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_dict(df):\n",
    "    for column in dict_columns:\n",
    "        df[column] = df[column].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = text_to_dict(train)\n",
    "test = text_to_dict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collection\n",
    "\n",
    "train['collection_name'] = train['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\n",
    "train['has_collection'] = train['belongs_to_collection'].apply(lambda x: len(x) if x != {} else 0)\n",
    "\n",
    "test['collection_name'] = test['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\n",
    "test['has_collection'] = test['belongs_to_collection'].apply(lambda x: len(x) if x != {} else 0)\n",
    "\n",
    "train = train.drop(['belongs_to_collection'], axis=1)\n",
    "test = test.drop(['belongs_to_collection'], axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Genres\n",
    "\n",
    "list_of_genres = list(train['genres'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n",
    "\n",
    "train['num_genres'] = train['genres'].apply(lambda x: len(x) if x != {} else 0)\n",
    "train['all_genres'] = train['genres'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n",
    "top_genres = [m[0] for m in Counter([i for j in list_of_genres for i in j]).most_common(10)]\n",
    "for g in top_genres:\n",
    "    train['genre_' + g] = train['all_genres'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "test['num_genres'] = test['genres'].apply(lambda x: len(x) if x != {} else 0)\n",
    "test['all_genres'] = test['genres'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n",
    "for g in top_genres:\n",
    "    test['genre_' + g] = test['all_genres'].apply(lambda x: 1 if g in x else 0)    \n",
    "    \n",
    "train = train.drop(['genres'], axis=1)\n",
    "test = test.drop(['genres'], axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homepage\n",
    "\n",
    "train['homepage'] = train['homepage'].fillna(0)\n",
    "train['homepage'] = train['homepage'].apply(lambda x: 0 if x==0 else 1)\n",
    "\n",
    "test['homepage'] = test['homepage'].fillna(0)\n",
    "test['homepage'] = test['homepage'].apply(lambda x: 0 if x==0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Production companies\n",
    "\n",
    "list_of_companies = list(train['production_companies'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n",
    "\n",
    "train['num_companies'] = train['production_companies'].apply(lambda x: len(x) if x != {} else 0)\n",
    "train['all_production_companies'] = train['production_companies'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n",
    "top_companies = [m[0] for m in Counter([i for j in list_of_companies for i in j]).most_common(20)]\n",
    "for g in top_companies:\n",
    "    train['production_company_' + g] = train['all_production_companies'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "test['num_companies'] = test['production_companies'].apply(lambda x: len(x) if x != {} else 0)\n",
    "test['all_production_companies'] = test['production_companies'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n",
    "for g in top_companies:\n",
    "    test['production_company_' + g] = test['all_production_companies'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "train = train.drop(['production_companies', 'all_production_companies'], axis=1)\n",
    "test = test.drop(['production_companies', 'all_production_companies'], axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Production Countries\n",
    "\n",
    "list_of_countries = list(train['production_countries'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n",
    "\n",
    "train['num_countries'] = train['production_countries'].apply(lambda x: len(x) if x != {} else 0)\n",
    "train['all_countries'] = train['production_countries'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n",
    "top_countries = [m[0] for m in Counter([i for j in list_of_countries for i in j]).most_common(25)]\n",
    "for g in top_countries:\n",
    "    train['production_country_' + g] = train['all_countries'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "test['num_countries'] = test['production_countries'].apply(lambda x: len(x) if x != {} else 0)\n",
    "test['all_countries'] = test['production_countries'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n",
    "for g in top_countries:\n",
    "    test['production_country_' + g] = test['all_countries'].apply(lambda x: 1 if g in x else 0)\n",
    "\n",
    "train = train.drop(['production_countries', 'all_countries'], axis=1)\n",
    "test = test.drop(['production_countries', 'all_countries'], axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# languages\n",
    "\n",
    "list_of_languages = list(train['spoken_languages'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n",
    "\n",
    "train['num_languages'] = train['spoken_languages'].apply(lambda x: len(x) if x != {} else 0)\n",
    "train['all_languages'] = train['spoken_languages'].apply(lambda x: ' '.join(sorted([i['iso_639_1'] for i in x])) if x != {} else {})\n",
    "top_languages = [m[0] for m in Counter([i for j in list_of_languages for i in j]).most_common(20)]\n",
    "for g in top_languages:\n",
    "    train['language_' + g] = train['all_languages'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "test['num_languages'] = test['spoken_languages'].apply(lambda x: len(x) if x != {} else 0)\n",
    "test['all_languages'] = test['spoken_languages'].apply(lambda x: ' '.join(sorted([i['iso_639_1'] for i in x])) if x != {} else {})\n",
    "for g in top_languages:\n",
    "    test['language_' + g] = test['all_languages'].apply(lambda x: 1 if g in x else 0)\n",
    "\n",
    "train = train.drop(['spoken_languages', 'all_languages'], axis=1)\n",
    "test = test.drop(['spoken_languages', 'all_languages'], axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keywords\n",
    "\n",
    "list_of_keywords = list(train['Keywords'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n",
    "\n",
    "train['num_Keywords'] = train['Keywords'].apply(lambda x: len(x) if x != {} else 0)\n",
    "train['all_Keywords'] = train['Keywords'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n",
    "top_keywords = [m[0] for m in Counter([i for j in list_of_keywords for i in j]).most_common(20)]\n",
    "for g in top_keywords:\n",
    "    train['keyword_' + g] = train['all_Keywords'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "test['num_Keywords'] = test['Keywords'].apply(lambda x: len(x) if x != {} else 0)\n",
    "test['all_Keywords'] = test['Keywords'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n",
    "for g in top_keywords:\n",
    "    test['keyword_' + g] = test['all_Keywords'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "train = train.drop(['Keywords', 'all_Keywords'], axis=1)\n",
    "test = test.drop(['Keywords', 'all_Keywords'], axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cast\n",
    "\n",
    "list_of_cast_names = list(train['cast'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n",
    "list_of_cast_gender = list(train['cast'].apply(lambda x: [i['gender'] for i in x] if x != {} else []).values)\n",
    "list_of_cast_characters = list(train['cast'].apply(lambda x: [i['character'] for i in x] if x != {} else []).values)\n",
    "\n",
    "train['num_cast'] = train['cast'].apply(lambda x: len(x) if x != {} else 0)\n",
    "top_cast_names = [m[0] for m in Counter([i for j in list_of_cast_names for i in j]).most_common(15)]\n",
    "for g in top_cast_names:\n",
    "    train['cast_name_' + g] = train['cast'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "train['gender_0'] = train['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\n",
    "train['gender_1'] = train['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\n",
    "train['gender_2'] = train['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n",
    "\n",
    "top_cast_characters = [m[0] for m in Counter([i for j in list_of_cast_characters for i in j]).most_common(10)]\n",
    "for g in top_cast_characters:\n",
    "    train['cast_character_' + g] = train['cast'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "test['num_cast'] = test['cast'].apply(lambda x: len(x) if x != {} else 0)\n",
    "for g in top_cast_names:\n",
    "    test['cast_name_' + g] = test['cast'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "test['gender_0'] = test['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\n",
    "test['gender_1'] = test['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\n",
    "test['gender_2'] = test['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n",
    "\n",
    "for g in top_cast_characters:\n",
    "    test['cast_character_' + g] = test['cast'].apply(lambda x: 1 if g in x else 0)\n",
    "\n",
    "train = train.drop(['cast'], axis=1)\n",
    "test = test.drop(['cast'], axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crew\n",
    "\n",
    "list_of_crew_names = list(train['crew'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n",
    "list_of_crew_jobs = list(train['crew'].apply(lambda x: [i['job'] for i in x] if x != {} else []).values)\n",
    "list_of_crew_genders = list(train['crew'].apply(lambda x: [i['gender'] for i in x] if x != {} else []).values)\n",
    "list_of_crew_departments = list(train['crew'].apply(lambda x: [i['department'] for i in x] if x != {} else []).values)\n",
    "\n",
    "train['num_crew'] = train['crew'].apply(lambda x: len(x) if x != {} else 0)\n",
    "top_crew_names = [m[0] for m in Counter([i for j in list_of_crew_names for i in j]).most_common(15)]\n",
    "for g in top_crew_names:\n",
    "    train['crew_name_' + g] = train['crew'].apply(lambda x: 1 if g in x else 0)\n",
    "\n",
    "train['genders_0'] = train['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\n",
    "train['genders_1'] = train['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\n",
    "train['genders_2'] = train['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n",
    "\n",
    "top_cast_characters = [m[0] for m in Counter([i for j in list_of_cast_characters for i in j]).most_common(15)]\n",
    "for g in top_cast_characters:\n",
    "    train['crew_character_' + g] = train['crew'].apply(lambda x: 1 if g in x else 0)\n",
    "\n",
    "top_crew_jobs = [m[0] for m in Counter([i for j in list_of_crew_jobs for i in j]).most_common(15)]\n",
    "for j in top_crew_jobs:\n",
    "    train['jobs_' + j] = train['crew'].apply(lambda x: sum([1 for i in x if i['job'] == j]))\n",
    "\n",
    "top_crew_departments = [m[0] for m in Counter([i for j in list_of_crew_departments for i in j]).most_common(15)]\n",
    "for j in top_crew_departments:\n",
    "    train['departments_' + j] = train['crew'].apply(lambda x: sum([1 for i in x if i['department'] == j])) \n",
    "    \n",
    "test['num_crew'] = test['crew'].apply(lambda x: len(x) if x != {} else 0)\n",
    "for g in top_crew_names:\n",
    "    test['crew_name_' + g] = test['crew'].apply(lambda x: 1 if g in x else 0)\n",
    "\n",
    "test['genders_0'] = test['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\n",
    "test['genders_1'] = test['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\n",
    "test['genders_2'] = test['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n",
    "\n",
    "for g in top_cast_characters:\n",
    "    test['crew_character_' + g] = test['crew'].apply(lambda x: 1 if g in x else 0)\n",
    "\n",
    "for j in top_crew_jobs:\n",
    "    test['jobs_' + j] = test['crew'].apply(lambda x: sum([1 for i in x if i['job'] == j]))\n",
    "\n",
    "for j in top_crew_departments:\n",
    "    test['departments_' + j] = test['crew'].apply(lambda x: sum([1 for i in x if i['department'] == j])) \n",
    "\n",
    "train = train.drop(['crew'], axis=1)\n",
    "test = test.drop(['crew'], axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['log_revenue'] = np.log1p(train['revenue'])\n",
    "\n",
    "train['log_budget'] = np.log1p(train['budget'])\n",
    "test['log_budget'] = np.log1p(test['budget'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lang = ['en', 'fr', 'ru', 'es', 'hi', 'ja', 'it', 'ko', 'cn', 'zh', 'de', 'ta']\n",
    "\n",
    "train['original_language'] = train['original_language'].apply(lambda x: x if x in list_of_lang else 'Other')\n",
    "test['original_language'] = test['original_language'].apply(lambda x: x if x in list_of_lang else 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_status = ['Released', 'Post Production', 'Rumored']\n",
    "\n",
    "train['status'] = train['status'].apply(lambda x: x if x in list_of_status else 'Other')\n",
    "test['status'] = test['status'].apply(lambda x: x if x in list_of_status else 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['original_language', 'collection_name', 'all_genres', 'status']:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(train[col].fillna('')) + list(test[col].fillna('')))\n",
    "    train[col] = le.transform(train[col].fillna('').astype(str))\n",
    "    test[col] = le.transform(test[col].fillna('').astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_date(x):\n",
    "\n",
    "    year = x.split('/')[2]\n",
    "    if int(year) <= 19:\n",
    "        return x[:-2] + '20' + year\n",
    "    else:\n",
    "        return x[:-2] + '19' + year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['release_date'].isnull() == True, 'release_date'] = '01/01/98'\n",
    "\n",
    "train['release_date'] = train['release_date'].apply(lambda x: fix_date(x))\n",
    "test['release_date'] = test['release_date'].apply(lambda x: fix_date(x))\n",
    "\n",
    "train['release_date'] = pd.to_datetime(train['release_date'])\n",
    "test['release_date'] = pd.to_datetime(test['release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date(df):\n",
    "    \n",
    "    date_parts = ['year', 'weekday', 'month', 'weekofyear', 'day', 'quarter']\n",
    "    for part in date_parts:\n",
    "        part_col = 'release_date' + \"_\" + part\n",
    "        df[part_col] = getattr(df['release_date'].dt, part).astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = process_date(train)\n",
    "test = process_date(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['title', 'tagline', 'overview', 'original_title']:\n",
    "    train['len_' + col] = train[col].fillna('').apply(lambda x: len(str(x)))\n",
    "    train['words_' + col] = train[col].fillna('').apply(lambda x: len(str(x.split(' '))))\n",
    "    train = train.drop(col, axis=1)\n",
    "    \n",
    "    test['len_' + col] = test[col].fillna('').apply(lambda x: len(str(x)))\n",
    "    test['words_' + col] = test[col].fillna('').apply(lambda x: len(str(x.split(' '))))\n",
    "    test = test.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train['log_revenue']\n",
    "train = train.drop(['id', 'budget', 'release_date', 'revenue', 'log_revenue', 'imdb_id', 'poster_path'], axis=1)\n",
    "test = test.drop(['id', 'budget', 'release_date', 'imdb_id', 'poster_path'], axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['budget_runtime_ratio'] = train['log_budget'] / train['runtime']\n",
    "test['budget_runtime_ratio'] = test['log_budget'] / test['runtime']\n",
    "\n",
    "train['budget_popularity_ratio'] = train['log_budget'] / train['popularity']\n",
    "test['budget_popularity_ratio'] = test['log_budget'] / test['popularity']\n",
    "\n",
    "train['releaseYear_popularity_ratio'] = train['release_date_year'] / train['popularity']\n",
    "test['releaseYear_popularity_ratio'] = test['release_date_year'] / test['popularity']\n",
    "\n",
    "train['releaseYear_popularity_ratio2'] = train['popularity'] / train['release_date_year']\n",
    "test['releaseYear_popularity_ratio2'] = test['popularity'] / test['release_date_year']\n",
    "\n",
    "\n",
    "train['meanRuntimeByYear'] = train.groupby('release_date_year')['runtime'].aggregate('mean')\n",
    "test['meanRuntimeByYear'] = test.groupby('release_date_year')['runtime'].aggregate('mean')\n",
    "\n",
    "train['meanPopularityByYear'] = train.groupby('release_date_year')['popularity'].aggregate('mean')\n",
    "test['meanPopularityByYear'] = test.groupby('release_date_year')['popularity'].aggregate('mean')\n",
    "\n",
    "train['meanBudgetByYear'] = train.groupby('release_date_year')['log_budget'].aggregate('mean')\n",
    "test['meanBudgetByYear'] = test.groupby('release_date_year')['log_budget'].aggregate('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "K = 10\n",
    "fold = list(KFold(K, shuffle=True, random_state=SEED).split(train))\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_model(trn_X, trn_y, val_X, val_y, test, verbose):\n",
    "    \n",
    "    params = {'objective': 'reg:linear',\n",
    "              'eta': 0.01, \n",
    "              'max_depth': 5,\n",
    "              'subsample': 0.6,\n",
    "              'colsample_bytree': 0.7,\n",
    "              'eval_metrics': 'rmse',\n",
    "              'seed': SEED,\n",
    "              'silent': True}\n",
    "    \n",
    "    record = dict()\n",
    "    \n",
    "    model = xgb.train(params, xgb.DMatrix(trn_X, trn_y), 1000,\n",
    "                      [(xgb.DMatrix(trn_X, trn_y), 'train'),\n",
    "                      (xgb.DMatrix(val_X, val_y), 'valid')],\n",
    "                      verbose_eval=verbose,\n",
    "                      early_stopping_rounds=200,\n",
    "                      callbacks=[xgb.callback.record_evaluation(record)])\n",
    "    \n",
    "    best_idx = np.argmin(np.array(record['valid']['rmse']))\n",
    "    \n",
    "    val_pred = model.predict(xgb.DMatrix(val_X), ntree_limit=model.best_ntree_limit)\n",
    "    test_pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n",
    "    \n",
    "    return {'val': val_pred, 'test': test_pred, 'error': record['valid']['rmse'][best_idx], 'importance': [i for k, i in model.get_score().items()]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n",
    "\n",
    "    params = {'objective':'regression',\n",
    "         'num_leaves' : 40,\n",
    "         'min_data_in_leaf' : 20,\n",
    "         'max_depth' : 5,\n",
    "         'learning_rate': 0.01,\n",
    "         'feature_fraction': 0.8,\n",
    "         'bagging_freq': 1,\n",
    "         'bagging_fraction': 0.8,\n",
    "         'bagging_seed': SEED,\n",
    "         'metric': 'rmse',\n",
    "         'random_state' : SEED,\n",
    "         'verbosity': -1}\n",
    "\n",
    "    record = dict()\n",
    "    model = lgb.train(params\n",
    "                      , lgb.Dataset(trn_x, trn_y)\n",
    "                      , num_boost_round = 10000\n",
    "                      , valid_sets = [lgb.Dataset(val_x, val_y)]\n",
    "                      , verbose_eval = verbose\n",
    "                      , early_stopping_rounds = 200\n",
    "                      , callbacks = [lgb.record_evaluation(record)]\n",
    "                     )\n",
    "    best_idx = np.argmin(np.array(record['valid_0']['rmse']))\n",
    "\n",
    "    val_pred = model.predict(val_x, num_iteration = model.best_iteration)\n",
    "    test_pred = model.predict(test, num_iteration = model.best_iteration)\n",
    "    \n",
    "    return {'val':val_pred, 'test':test_pred, 'error':record['valid_0']['rmse'][best_idx], 'importance':model.feature_importance('gain')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold.    RMSE\n",
      "xgb model. 2.07189 (0m)\n",
      "lgb model. 2.07891 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.07540\n",
      "blend err. 2.06753\n",
      "\n",
      "2 fold.    RMSE\n",
      "xgb model. 1.84405 (0m)\n",
      "lgb model. 1.86337 (0m)\n",
      "---------------------------\n",
      "avg   err. 1.85371\n",
      "blend err. 1.84155\n",
      "\n",
      "3 fold.    RMSE\n",
      "xgb model. 1.90279 (0m)\n",
      "lgb model. 1.91496 (0m)\n",
      "---------------------------\n",
      "avg   err. 1.90888\n",
      "blend err. 1.89757\n",
      "\n",
      "4 fold.    RMSE\n",
      "xgb model. 1.89123 (0m)\n",
      "lgb model. 1.90223 (0m)\n",
      "---------------------------\n",
      "avg   err. 1.89673\n",
      "blend err. 1.88534\n",
      "\n",
      "5 fold.    RMSE\n",
      "xgb model. 2.15304 (0m)\n",
      "lgb model. 2.17077 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.16190\n",
      "blend err. 2.15442\n",
      "\n",
      "6 fold.    RMSE\n",
      "xgb model. 1.86254 (0m)\n",
      "lgb model. 1.86528 (0m)\n",
      "---------------------------\n",
      "avg   err. 1.86391\n",
      "blend err. 1.84991\n",
      "\n",
      "7 fold.    RMSE\n",
      "xgb model. 2.44035 (0m)\n",
      "lgb model. 2.43434 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.43735\n",
      "blend err. 2.42859\n",
      "\n",
      "8 fold.    RMSE\n",
      "xgb model. 2.19149 (0m)\n",
      "lgb model. 2.20287 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.19718\n",
      "blend err. 2.18157\n",
      "\n",
      "9 fold.    RMSE\n",
      "xgb model. 2.27868 (0m)\n",
      "lgb model. 2.29262 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.28565\n",
      "blend err. 2.27601\n",
      "\n",
      "10 fold.    RMSE\n",
      "xgb model. 2.05785 (0m)\n",
      "lgb model. 2.06662 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.06223\n",
      "blend err. 2.03755\n",
      "\n",
      "fianl avg   err. 2.0742937181914956\n",
      "fianl blend err. 2.070605968949825\n"
     ]
    }
   ],
   "source": [
    "result_dict = dict()\n",
    "val_pred = np.zeros(train.shape[0])\n",
    "test_pred = np.zeros(test.shape[0])\n",
    "final_err = 0\n",
    "verbose = False\n",
    "\n",
    "for i, (trn, val) in enumerate(fold) :\n",
    "    print(i+1, \"fold.    RMSE\")\n",
    "    \n",
    "    trn_x = train.loc[trn, :]\n",
    "    trn_y = y[trn]\n",
    "    val_x = train.loc[val, :]\n",
    "    val_y = y[val]\n",
    "    \n",
    "    fold_val_pred = []\n",
    "    fold_test_pred = []\n",
    "    fold_err = []\n",
    "    \n",
    "    \n",
    "    start = datetime.now()\n",
    "    result = xgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val'])\n",
    "    fold_test_pred.append(result['test'])\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"xgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    \n",
    "    start = datetime.now()\n",
    "    result = lgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val'])\n",
    "    fold_test_pred.append(result['test'])\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"lgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    \n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    result = cat_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val'])\n",
    "    fold_test_pred.append(result['test'])\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"cat model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    \"\"\"\n",
    "    \n",
    "    val_pred[val] += np.mean(np.array(fold_val_pred), axis = 0)\n",
    "    test_pred += np.mean(np.array(fold_test_pred), axis = 0) / K\n",
    "    final_err += (sum(fold_err) / len(fold_err)) / K\n",
    "    \n",
    "    print(\"---------------------------\")\n",
    "    print(\"avg   err.\", \"{0:.5f}\".format(sum(fold_err) / len(fold_err)))\n",
    "    print(\"blend err.\", \"{0:.5f}\".format(np.sqrt(np.mean((np.mean(np.array(fold_val_pred), axis = 0) - val_y)**2))))\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "print(\"fianl avg   err.\", final_err)\n",
    "print(\"fianl blend err.\", np.sqrt(np.mean((val_pred - y)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('data/sample_submission.csv')\n",
    "df_sub = pd.DataFrame()\n",
    "df_sub['id'] = sub['id']\n",
    "df_sub['revenue'] = np.expm1(test_pred)\n",
    "df_sub.to_csv(\"new_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
