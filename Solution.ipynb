{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from prepare_data import prepare\n",
    "from load_data import load\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data/trainRatingTotalVotes.csv' does not exist: b'data/trainRatingTotalVotes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4efc0b5cbfd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Notebooks/TMDB_Box_Office_Prediction/load_data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'revenue'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/trainRatingTotalVotes.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imdb_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/testRatingTotalVotes.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imdb_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data/trainRatingTotalVotes.csv' does not exist: b'data/trainRatingTotalVotes.csv'"
     ]
    }
   ],
   "source": [
    "train, test, y, train_dict = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1082"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['collection_name'] = train['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\n",
    "train['has_collection'] = train['belongs_to_collection'].apply(lambda x: len(x) if x != {} else 0)\n",
    "\n",
    "test['collection_name'] = test['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\n",
    "test['has_collection'] = test['belongs_to_collection'].apply(lambda x: len(x) if x != {} else 0)\n",
    "\n",
    "train = train.drop(['belongs_to_collection'], axis=1)\n",
    "test = test.drop(['belongs_to_collection'], axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = prepare(pd.concat([train, test]).reset_index(drop=True), train_dict)\n",
    "\n",
    "train = all_data.loc[:train.shape[0] -1,:]\n",
    "test = all_data.loc[train.shape[0]:,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "K = 10\n",
    "fold = list(KFold(K, shuffle=True, random_state=SEED).split(train))\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_model(trn_X, trn_y, val_X, val_y, test, verbose):\n",
    "    \n",
    "    params = {'objective': 'reg:linear',\n",
    "              'eta': 0.01, \n",
    "              'max_depth': 5,\n",
    "              'subsample': 0.6,\n",
    "              'colsample_bytree': 0.7,\n",
    "              'eval_metrics': 'rmse',\n",
    "              'seed': SEED,\n",
    "              'silent': True}\n",
    "    \n",
    "    record = dict()\n",
    "    \n",
    "    model = xgb.train(params, xgb.DMatrix(trn_X, trn_y), 1000,\n",
    "                      [(xgb.DMatrix(trn_X, trn_y), 'train'),\n",
    "                      (xgb.DMatrix(val_X, val_y), 'valid')],\n",
    "                      verbose_eval=verbose,\n",
    "                      early_stopping_rounds=200,\n",
    "                      callbacks=[xgb.callback.record_evaluation(record)])\n",
    "    \n",
    "    best_idx = np.argmin(np.array(record['valid']['rmse']))\n",
    "    \n",
    "    val_pred = model.predict(xgb.DMatrix(val_X), ntree_limit=model.best_ntree_limit)\n",
    "    test_pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n",
    "    \n",
    "    return {'val': val_pred, 'test': test_pred, 'error': record['valid']['rmse'][best_idx], 'importance': [i for k, i in model.get_score().items()]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n",
    "\n",
    "    params = {'objective':'regression',\n",
    "         'num_leaves' : 40,\n",
    "         'min_data_in_leaf' : 20,\n",
    "         'max_depth' : 5,\n",
    "         'learning_rate': 0.01,\n",
    "         'feature_fraction': 0.8,\n",
    "         'bagging_freq': 1,\n",
    "         'bagging_fraction': 0.8,\n",
    "         'bagging_seed': SEED,\n",
    "         'metric': 'rmse',\n",
    "         'random_state' : SEED,\n",
    "         'verbosity': -1}\n",
    "\n",
    "    record = dict()\n",
    "    model = lgb.train(params\n",
    "                      , lgb.Dataset(trn_x, trn_y)\n",
    "                      , num_boost_round = 10000\n",
    "                      , valid_sets = [lgb.Dataset(val_x, val_y)]\n",
    "                      , verbose_eval = verbose\n",
    "                      , early_stopping_rounds = 200\n",
    "                      , callbacks = [lgb.record_evaluation(record)]\n",
    "                     )\n",
    "    best_idx = np.argmin(np.array(record['valid_0']['rmse']))\n",
    "\n",
    "    val_pred = model.predict(val_x, num_iteration = model.best_iteration)\n",
    "    test_pred = model.predict(test, num_iteration = model.best_iteration)\n",
    "    \n",
    "    return {'val':val_pred, 'test':test_pred, 'error':record['valid_0']['rmse'][best_idx], 'importance':model.feature_importance('gain')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n",
    "    \n",
    "    model = CatBoostRegressor(iterations=10000,\n",
    "                                 learning_rate=0.01,\n",
    "                                 depth=5,\n",
    "                                 eval_metric='RMSE',\n",
    "                                 colsample_bylevel=0.7,\n",
    "                                 random_seed = SEED,\n",
    "                                 bagging_temperature = 0.2,\n",
    "                                 metric_period = None\n",
    "                                )\n",
    "    model.fit(trn_x, trn_y,\n",
    "                 eval_set=(val_x, val_y),\n",
    "                 use_best_model=True,\n",
    "                 verbose=False)\n",
    "    \n",
    "    val_pred = model.predict(val_x)\n",
    "    test_pred = model.predict(test)\n",
    "    \n",
    "    return {'val':val_pred, 'test':test_pred, 'error':model.get_best_score()['validation_0']['RMSE'], 'importance':model.get_feature_importance()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold.    RMSE\n",
      "xgb model. 2.20203 (0m)\n",
      "lgb model. 2.18165 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.19184\n",
      "blend err. 2.18668\n",
      "\n",
      "2 fold.    RMSE\n",
      "xgb model. 2.60756 (0m)\n",
      "lgb model. 2.57574 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.59165\n",
      "blend err. 2.58534\n",
      "\n",
      "3 fold.    RMSE\n",
      "xgb model. 2.32793 (0m)\n",
      "lgb model. 2.29481 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.31137\n",
      "blend err. 2.30251\n",
      "\n",
      "4 fold.    RMSE\n",
      "xgb model. 2.29672 (0m)\n",
      "lgb model. 2.24911 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.27291\n",
      "blend err. 2.26502\n",
      "\n",
      "5 fold.    RMSE\n",
      "xgb model. 2.43987 (0m)\n",
      "lgb model. 2.44855 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.44421\n",
      "blend err. 2.43433\n",
      "\n",
      "6 fold.    RMSE\n",
      "xgb model. 2.33555 (0m)\n",
      "lgb model. 2.32395 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.32975\n",
      "blend err. 2.32382\n",
      "\n",
      "7 fold.    RMSE\n",
      "xgb model. 2.16296 (0m)\n",
      "lgb model. 2.14415 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.15356\n",
      "blend err. 2.14695\n",
      "\n",
      "8 fold.    RMSE\n",
      "xgb model. 2.29163 (0m)\n",
      "lgb model. 2.28621 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.28892\n",
      "blend err. 2.28290\n",
      "\n",
      "9 fold.    RMSE\n",
      "xgb model. 2.11998 (0m)\n",
      "lgb model. 2.08837 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.10417\n",
      "blend err. 2.09808\n",
      "\n",
      "10 fold.    RMSE\n",
      "xgb model. 2.35540 (0m)\n",
      "lgb model. 2.33697 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.34618\n",
      "blend err. 2.34172\n",
      "\n",
      "fianl avg   err. 2.3034559611094596\n",
      "fianl blend err. 2.3006543778546416\n"
     ]
    }
   ],
   "source": [
    "result_dict = dict()\n",
    "val_pred = np.zeros(train.shape[0])\n",
    "test_pred = np.zeros(test.shape[0])\n",
    "final_err = 0\n",
    "verbose = False\n",
    "\n",
    "for i, (trn, val) in enumerate(fold) :\n",
    "    print(i+1, \"fold.    RMSE\")\n",
    "    \n",
    "    trn_x = train.loc[trn, :]\n",
    "    trn_y = y[trn]\n",
    "    val_x = train.loc[val, :]\n",
    "    val_y = y[val]\n",
    "    \n",
    "    fold_val_pred = []\n",
    "    fold_test_pred = []\n",
    "    fold_err = []\n",
    "    \n",
    "    \n",
    "    start = datetime.now()\n",
    "    result = xgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val'])\n",
    "    fold_test_pred.append(result['test'])\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"xgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    \n",
    "    start = datetime.now()\n",
    "    result = lgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val'])\n",
    "    fold_test_pred.append(result['test'])\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"lgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    \n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    result = cat_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val'])\n",
    "    fold_test_pred.append(result['test'])\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"cat model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    \"\"\"\n",
    "    \n",
    "    val_pred[val] += np.mean(np.array(fold_val_pred), axis = 0)\n",
    "    test_pred += np.mean(np.array(fold_test_pred), axis = 0) / K\n",
    "    final_err += (sum(fold_err) / len(fold_err)) / K\n",
    "    \n",
    "    print(\"---------------------------\")\n",
    "    print(\"avg   err.\", \"{0:.5f}\".format(sum(fold_err) / len(fold_err)))\n",
    "    print(\"blend err.\", \"{0:.5f}\".format(np.sqrt(np.mean((np.mean(np.array(fold_val_pred), axis = 0) - val_y)**2))))\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "print(\"fianl avg   err.\", final_err)\n",
    "print(\"fianl blend err.\", np.sqrt(np.mean((val_pred - y)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('data/sample_submission.csv')\n",
    "df_sub = pd.DataFrame()\n",
    "df_sub['id'] = sub['id']\n",
    "df_sub['revenue'] = np.expm1(test_pred)\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_model_2(trn_X, trn_y, val_X, val_y, test, verbose):\n",
    "    \n",
    "    params = {'objective': 'reg:linear',\n",
    "              'eta': 0.1, \n",
    "              'max_depth': 3,\n",
    "              'subsample': 0.4,\n",
    "              'colsample_bytree': 0.5,\n",
    "              'eval_metrics': 'rmse',\n",
    "              'seed': SEED,\n",
    "              'silent': True}\n",
    "    \n",
    "    record = dict()\n",
    "    \n",
    "    model = xgb.train(params, xgb.DMatrix(trn_X, trn_y), 1000,\n",
    "                      [(xgb.DMatrix(trn_X, trn_y), 'train'),\n",
    "                      (xgb.DMatrix(val_X, val_y), 'valid')],\n",
    "                      verbose_eval=verbose,\n",
    "                      early_stopping_rounds=200,\n",
    "                      callbacks=[xgb.callback.record_evaluation(record)])\n",
    "    \n",
    "    best_idx = np.argmin(np.array(record['valid']['rmse']))\n",
    "    \n",
    "    val_pred = model.predict(xgb.DMatrix(val_X), ntree_limit=model.best_ntree_limit)\n",
    "    test_pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n",
    "    \n",
    "    return {'val': val_pred, 'test': test_pred, 'error': record['valid']['rmse'][best_idx], 'importance': [i for k, i in model.get_score().items()]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model_2(trn_x, trn_y, val_x, val_y, test, verbose) :\n",
    "\n",
    "    params = {'objective':'regression_l2',\n",
    "         'num_leaves' : 50,\n",
    "         'min_data_in_leaf' : 15,\n",
    "         'max_depth' : 4,\n",
    "         'learning_rate': 0.01,\n",
    "         'feature_fraction': 0.8,\n",
    "         'bagging_freq': 1,\n",
    "         'bagging_fraction': 0.8,\n",
    "         'bagging_seed': SEED,\n",
    "         'metric': 'rmse',\n",
    "         'random_state' : SEED,\n",
    "         'verbosity': -1}\n",
    "\n",
    "    record = dict()\n",
    "    model = lgb.train(params\n",
    "                      , lgb.Dataset(trn_x, trn_y)\n",
    "                      , num_boost_round = 10000\n",
    "                      , valid_sets = [lgb.Dataset(val_x, val_y)]\n",
    "                      , verbose_eval = verbose\n",
    "                      , early_stopping_rounds = 200\n",
    "                      , callbacks = [lgb.record_evaluation(record)]\n",
    "                     )\n",
    "    best_idx = np.argmin(np.array(record['valid_0']['rmse']))\n",
    "\n",
    "    val_pred = model.predict(val_x, num_iteration = model.best_iteration)\n",
    "    test_pred = model.predict(test, num_iteration = model.best_iteration)\n",
    "    \n",
    "    return {'val':val_pred, 'test':test_pred, 'error':record['valid_0']['rmse'][best_idx], 'importance':model.feature_importance('gain')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold.    RMSE\n",
      "xgb model. 2.20590 (0m)\n",
      "lgb model. 2.19485 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.20037\n",
      "blend err. 2.18922\n",
      "\n",
      "2 fold.    RMSE\n",
      "xgb model. 2.61319 (0m)\n",
      "lgb model. 2.56509 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.58914\n",
      "blend err. 2.56123\n",
      "\n",
      "3 fold.    RMSE\n",
      "xgb model. 2.33092 (0m)\n",
      "lgb model. 2.29304 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.31198\n",
      "blend err. 2.29923\n",
      "\n",
      "4 fold.    RMSE\n",
      "xgb model. 2.31830 (0m)\n",
      "lgb model. 2.24868 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.28349\n",
      "blend err. 2.26996\n",
      "\n",
      "5 fold.    RMSE\n",
      "xgb model. 2.40779 (0m)\n",
      "lgb model. 2.42948 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.41863\n",
      "blend err. 2.40144\n",
      "\n",
      "6 fold.    RMSE\n",
      "xgb model. 2.37108 (0m)\n",
      "lgb model. 2.30686 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.33897\n",
      "blend err. 2.32200\n",
      "\n",
      "7 fold.    RMSE\n",
      "xgb model. 2.18863 (0m)\n",
      "lgb model. 2.14278 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.16571\n",
      "blend err. 2.14810\n",
      "\n",
      "8 fold.    RMSE\n",
      "xgb model. 2.36428 (0m)\n",
      "lgb model. 2.29333 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.32880\n",
      "blend err. 2.31397\n",
      "\n",
      "9 fold.    RMSE\n",
      "xgb model. 2.19199 (0m)\n",
      "lgb model. 2.09234 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.14217\n",
      "blend err. 2.12887\n",
      "\n",
      "10 fold.    RMSE\n",
      "xgb model. 2.37581 (0m)\n",
      "lgb model. 2.34995 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.36288\n",
      "blend err. 2.34794\n",
      "\n",
      "fianl avg   err. 2.31421399890115\n",
      "fianl blend err. 2.3013930401165923\n"
     ]
    }
   ],
   "source": [
    "result_dict_2 = dict()\n",
    "val_pred_2 = np.zeros(train.shape[0])\n",
    "test_pred_2 = np.zeros(test.shape[0])\n",
    "final_err_2 = 0\n",
    "verbose = False\n",
    "\n",
    "for i, (trn, val) in enumerate(fold) :\n",
    "    print(i+1, \"fold.    RMSE\")\n",
    "    \n",
    "    trn_x = train.loc[trn, :]\n",
    "    trn_y = y[trn]\n",
    "    val_x = train.loc[val, :]\n",
    "    val_y = y[val]\n",
    "    \n",
    "    fold_val_pred = []\n",
    "    fold_test_pred = []\n",
    "    fold_err = []\n",
    "    \n",
    "    \n",
    "    start = datetime.now()\n",
    "    result = xgb_model_2(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val'])\n",
    "    fold_test_pred.append(result['test'])\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"xgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    \n",
    "    start = datetime.now()\n",
    "    result = lgb_model_2(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val'])\n",
    "    fold_test_pred.append(result['test'])\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"lgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    \n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    result = cat_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val'])\n",
    "    fold_test_pred.append(result['test'])\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"cat model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    \"\"\"\n",
    "    \n",
    "    val_pred_2[val] += np.mean(np.array(fold_val_pred), axis = 0)\n",
    "    test_pred_2 += np.mean(np.array(fold_test_pred), axis = 0) / K\n",
    "    final_err_2 += (sum(fold_err) / len(fold_err)) / K\n",
    "    \n",
    "    print(\"---------------------------\")\n",
    "    print(\"avg   err.\", \"{0:.5f}\".format(sum(fold_err) / len(fold_err)))\n",
    "    print(\"blend err.\", \"{0:.5f}\".format(np.sqrt(np.mean((np.mean(np.array(fold_val_pred), axis = 0) - val_y)**2))))\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "print(\"fianl avg   err.\", final_err_2)\n",
    "print(\"fianl blend err.\", np.sqrt(np.mean((val_pred_2 - y)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('data/sample_submission.csv')\n",
    "df_sub = pd.DataFrame()\n",
    "df_sub['id'] = sub['id']\n",
    "df_sub['revenue'] = np.expm1(test_pred_2)\n",
    "df_sub.to_csv(\"submission_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.read_csv('submission.csv')\n",
    "sub2 = pd.read_csv('submission_2.csv')\n",
    "sub3 = pd.read_csv('new_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_sub = sub1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_sub['revenue'] = .2*sub1['revenue'] + .45*sub2['revenue'] + .35*sub3['revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_sub.to_csv('fin_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
