{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from prepare_data import prepare\n",
    "from load_data import load\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 8/8 [00:08<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "train, test, y, train_dict = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = prepare(pd.concat([train, test]).reset_index(drop=True), train_dict)\n",
    "\n",
    "train = all_data.loc[:train.shape[0] -1,:]\n",
    "test = all_data.loc[train.shape[0]:,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "K = 20\n",
    "fold = list(KFold(K, shuffle=True, random_state=SEED).split(train))\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_model(trn_X, trn_y, val_X, val_y, test, verbose):\n",
    "    \n",
    "    params = {'objective': 'reg:linear',\n",
    "              'eta': 0.01, \n",
    "              'max_depth': 5,\n",
    "              'subsample': 0.6,\n",
    "              'colsample_bytree': 0.7,\n",
    "              'eval_metrics': 'rmse',\n",
    "              'seed': SEED,\n",
    "              'silent': True}\n",
    "    \n",
    "    record = dict()\n",
    "    \n",
    "    model = xgb.train(params, xgb.DMatrix(trn_X, trn_y), 1000,\n",
    "                      [(xgb.DMatrix(trn_X, trn_y), 'train'),\n",
    "                      (xgb.DMatrix(val_X, val_y), 'valid')],\n",
    "                      verbose_eval=verbose,\n",
    "                      early_stopping_rounds=200,\n",
    "                      callbacks=[xgb.callback.record_evaluation(record)])\n",
    "    \n",
    "    best_idx = np.argmin(np.array(record['valid']['rmse']))\n",
    "    \n",
    "    val_pred = model.predict(xgb.DMatrix(val_X), ntree_limit=model.best_ntree_limit)\n",
    "    test_pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n",
    "    \n",
    "    return {'val': val_pred, 'test': test_pred, 'error': record['valid']['rmse'][best_idx], 'importance': [i for k, i in model.get_score().items()]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n",
    "\n",
    "    params = {'objective':'regression',\n",
    "         'num_leaves' : 40,\n",
    "         'min_data_in_leaf' : 20,\n",
    "         'max_depth' : 5,\n",
    "         'learning_rate': 0.01,\n",
    "         'feature_fraction': 0.8,\n",
    "         'bagging_freq': 1,\n",
    "         'bagging_fraction': 0.8,\n",
    "         'bagging_seed': SEED,\n",
    "         'metric': 'rmse',\n",
    "         'random_state' : SEED,\n",
    "         'verbosity': -1}\n",
    "\n",
    "    record = dict()\n",
    "    model = lgb.train(params\n",
    "                      , lgb.Dataset(trn_x, trn_y)\n",
    "                      , num_boost_round = 10000\n",
    "                      , valid_sets = [lgb.Dataset(val_x, val_y)]\n",
    "                      , verbose_eval = verbose\n",
    "                      , early_stopping_rounds = 200\n",
    "                      , callbacks = [lgb.record_evaluation(record)]\n",
    "                     )\n",
    "    best_idx = np.argmin(np.array(record['valid_0']['rmse']))\n",
    "\n",
    "    val_pred = model.predict(val_x, num_iteration = model.best_iteration)\n",
    "    test_pred = model.predict(test, num_iteration = model.best_iteration)\n",
    "    \n",
    "    return {'val':val_pred, 'test':test_pred, 'error':record['valid_0']['rmse'][best_idx], 'importance':model.feature_importance('gain')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n",
    "    \n",
    "    model = CatBoostRegressor(iterations=10000,\n",
    "                                 learning_rate=0.01,\n",
    "                                 depth=5,\n",
    "                                 eval_metric='RMSE',\n",
    "                                 colsample_bylevel=0.7,\n",
    "                                 random_seed = SEED,\n",
    "                                 bagging_temperature = 0.2,\n",
    "                                 metric_period = None\n",
    "                                )\n",
    "    model.fit(trn_x, trn_y,\n",
    "                 eval_set=(val_x, val_y),\n",
    "                 use_best_model=True,\n",
    "                 verbose=False)\n",
    "    \n",
    "    val_pred = model.predict(val_x)\n",
    "    test_pred = model.predict(test)\n",
    "    \n",
    "    return {'val':val_pred, 'test':test_pred, 'error':model.get_best_score()['validation_0']['RMSE'], 'importance':model.get_feature_importance()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold.    RMSE\n",
      "xgb model. 2.42280 (0m)\n",
      "lgb model. 2.38370 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.40325\n",
      "blend err. 2.39855\n",
      "\n",
      "2 fold.    RMSE\n",
      "xgb model. 1.88623 (0m)\n",
      "lgb model. 1.90674 (0m)\n",
      "---------------------------\n",
      "avg   err. 1.89648\n",
      "blend err. 1.89094\n",
      "\n",
      "3 fold.    RMSE\n",
      "xgb model. 2.51339 (0m)\n",
      "lgb model. 2.50953 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.51146\n",
      "blend err. 2.50742\n",
      "\n",
      "4 fold.    RMSE\n",
      "xgb model. 2.77619 (0m)\n",
      "lgb model. 2.66536 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.72077\n",
      "blend err. 2.70599\n",
      "\n",
      "5 fold.    RMSE\n",
      "xgb model. 2.36520 (0m)\n",
      "lgb model. 2.32089 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.34305\n",
      "blend err. 2.33271\n",
      "\n",
      "6 fold.    RMSE\n",
      "xgb model. 2.27696 (0m)\n",
      "lgb model. 2.23293 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.25494\n",
      "blend err. 2.24636\n",
      "\n",
      "7 fold.    RMSE\n",
      "xgb model. 2.68177 (0m)\n",
      "lgb model. 2.58924 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.63550\n",
      "blend err. 2.62825\n",
      "\n",
      "8 fold.    RMSE\n",
      "xgb model. 1.78508 (0m)\n",
      "lgb model. 1.79290 (0m)\n",
      "---------------------------\n",
      "avg   err. 1.78899\n",
      "blend err. 1.78274\n",
      "\n",
      "9 fold.    RMSE\n",
      "xgb model. 2.29816 (0m)\n",
      "lgb model. 2.33095 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.31455\n",
      "blend err. 2.30936\n",
      "\n",
      "10 fold.    RMSE\n",
      "xgb model. 2.48179 (0m)\n",
      "lgb model. 2.50743 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.49461\n",
      "blend err. 2.48770\n",
      "\n",
      "11 fold.    RMSE\n",
      "xgb model. 2.20159 (0m)\n",
      "lgb model. 2.18743 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.19451\n",
      "blend err. 2.18937\n",
      "\n",
      "12 fold.    RMSE\n",
      "xgb model. 2.46384 (0m)\n",
      "lgb model. 2.39807 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.43096\n",
      "blend err. 2.42428\n",
      "\n",
      "13 fold.    RMSE\n",
      "xgb model. 2.18357 (0m)\n",
      "lgb model. 2.15482 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.16920\n",
      "blend err. 2.16266\n",
      "\n",
      "14 fold.    RMSE\n",
      "xgb model. 2.16054 (0m)\n",
      "lgb model. 2.14528 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.15291\n",
      "blend err. 2.14547\n",
      "\n",
      "15 fold.    RMSE\n",
      "xgb model. 2.54835 (0m)\n",
      "lgb model. 2.49544 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.52190\n",
      "blend err. 2.51173\n",
      "\n",
      "16 fold.    RMSE\n",
      "xgb model. 2.07073 (0m)\n",
      "lgb model. 2.04190 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.05631\n",
      "blend err. 2.04985\n",
      "\n",
      "17 fold.    RMSE\n",
      "xgb model. 1.70047 (0m)\n",
      "lgb model. 1.67477 (0m)\n",
      "---------------------------\n",
      "avg   err. 1.68762\n",
      "blend err. 1.67697\n",
      "\n",
      "18 fold.    RMSE\n",
      "xgb model. 2.49284 (0m)\n",
      "lgb model. 2.46480 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.47882\n",
      "blend err. 2.47567\n",
      "\n",
      "19 fold.    RMSE\n",
      "xgb model. 2.15327 (0m)\n",
      "lgb model. 2.10788 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.13058\n",
      "blend err. 2.12554\n",
      "\n",
      "20 fold.    RMSE\n",
      "xgb model. 2.53683 (0m)\n",
      "lgb model. 2.53984 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.53833\n",
      "blend err. 2.53320\n",
      "\n",
      "fianl avg   err. 2.286237415873608\n",
      "fianl blend err. 2.295332112109692\n"
     ]
    }
   ],
   "source": [
    "result_dict = dict()\n",
    "val_pred = np.zeros(train.shape[0])\n",
    "test_pred = np.zeros(test.shape[0])\n",
    "final_err = 0\n",
    "verbose = False\n",
    "\n",
    "for i, (trn, val) in enumerate(fold) :\n",
    "    print(i+1, \"fold.    RMSE\")\n",
    "    \n",
    "    trn_x = train.loc[trn, :]\n",
    "    trn_y = y[trn]\n",
    "    val_x = train.loc[val, :]\n",
    "    val_y = y[val]\n",
    "    \n",
    "    fold_val_pred = []\n",
    "    fold_test_pred = []\n",
    "    fold_err = []\n",
    "    \n",
    "    \n",
    "    start = datetime.now()\n",
    "    result = xgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val'])\n",
    "    fold_test_pred.append(result['test'])\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"xgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    \n",
    "    start = datetime.now()\n",
    "    result = lgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val'])\n",
    "    fold_test_pred.append(result['test'])\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"lgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    \n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    result = cat_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val'])\n",
    "    fold_test_pred.append(result['test'])\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"cat model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    \"\"\"\n",
    "    \n",
    "    val_pred[val] += np.mean(np.array(fold_val_pred), axis = 0)\n",
    "    test_pred += np.mean(np.array(fold_test_pred), axis = 0) / K\n",
    "    final_err += (sum(fold_err) / len(fold_err)) / K\n",
    "    \n",
    "    print(\"---------------------------\")\n",
    "    print(\"avg   err.\", \"{0:.5f}\".format(sum(fold_err) / len(fold_err)))\n",
    "    print(\"blend err.\", \"{0:.5f}\".format(np.sqrt(np.mean((np.mean(np.array(fold_val_pred), axis = 0) - val_y)**2))))\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "print(\"fianl avg   err.\", final_err)\n",
    "print(\"fianl blend err.\", np.sqrt(np.mean((val_pred - y)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('data/sample_submission.csv')\n",
    "df_sub = pd.DataFrame()\n",
    "df_sub['id'] = sub['id']\n",
    "df_sub['revenue'] = np.expm1(test_pred)\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
