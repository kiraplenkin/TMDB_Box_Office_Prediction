{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from prepare_data import prepare\n",
    "from load_data import load\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 8/8 [00:08<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "train, test, y, train_dict = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = prepare(pd.concat([train, test]).reset_index(drop=True), train_dict)\n",
    "\n",
    "train = all_data.loc[:train.shape[0] -1,:]\n",
    "test = all_data.loc[train.shape[0]:,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "K = 10\n",
    "fold = list(KFold(K, shuffle=True, random_state=SEED).split(train))\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_model(trn_X, trn_y, val_X, val_y, test, verbose):\n",
    "    \n",
    "    params = {'objective': 'reg:linear',\n",
    "              'eta': 0.01, \n",
    "              'max_depth': 5,\n",
    "              'subsample': 0.6,\n",
    "              'colsample_bytree': 0.7,\n",
    "              'eval_metrics': 'rmse',\n",
    "              'seed': SEED,\n",
    "              'silent': True}\n",
    "    \n",
    "    record = dict()\n",
    "    \n",
    "    model = xgb.train(params, xgb.DMatrix(trn_X, trn_y), 1000,\n",
    "                      [(xgb.DMatrix(trn_X, trn_y), 'train'),\n",
    "                      (xgb.DMatrix(val_X, val_y), 'valid')],\n",
    "                      verbose_eval=verbose,\n",
    "                      early_stopping_rounds=200,\n",
    "                      callbacks=[xgb.callback.record_evaluation(record)])\n",
    "    \n",
    "    best_idx = np.argmin(np.array(record['valid']['rmse']))\n",
    "    \n",
    "    val_pred = model.predict(xgb.DMatrix(val_X), ntree_limit=model.best_ntree_limit)\n",
    "    test_pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n",
    "    \n",
    "    return {'val': val_pred, 'test': test_pred, 'error': record['valid']['rmse'][best_idx], 'importance': [i for k, i in model.get_score().items()]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n",
    "\n",
    "    params = {'objective':'regression',\n",
    "         'num_leaves' : 40,\n",
    "         'min_data_in_leaf' : 20,\n",
    "         'max_depth' : 5,\n",
    "         'learning_rate': 0.01,\n",
    "         'feature_fraction': 0.8,\n",
    "         'bagging_freq': 1,\n",
    "         'bagging_fraction': 0.8,\n",
    "         'bagging_seed': SEED,\n",
    "         'metric': 'rmse',\n",
    "         'random_state' : SEED,\n",
    "         'verbosity': -1}\n",
    "\n",
    "    record = dict()\n",
    "    model = lgb.train(params\n",
    "                      , lgb.Dataset(trn_x, trn_y)\n",
    "                      , num_boost_round = 10000\n",
    "                      , valid_sets = [lgb.Dataset(val_x, val_y)]\n",
    "                      , verbose_eval = verbose\n",
    "                      , early_stopping_rounds = 200\n",
    "                      , callbacks = [lgb.record_evaluation(record)]\n",
    "                     )\n",
    "    best_idx = np.argmin(np.array(record['valid_0']['rmse']))\n",
    "\n",
    "    val_pred = model.predict(val_x, num_iteration = model.best_iteration)\n",
    "    test_pred = model.predict(test, num_iteration = model.best_iteration)\n",
    "    \n",
    "    return {'val':val_pred, 'test':test_pred, 'error':record['valid_0']['rmse'][best_idx], 'importance':model.feature_importance('gain')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n",
    "    \n",
    "    model = CatBoostRegressor(iterations=10000,\n",
    "                                 learning_rate=0.01,\n",
    "                                 depth=5,\n",
    "                                 eval_metric='RMSE',\n",
    "                                 colsample_bylevel=0.7,\n",
    "                                 random_seed = SEED,\n",
    "                                 bagging_temperature = 0.2,\n",
    "                                 metric_period = None\n",
    "                                )\n",
    "    model.fit(trn_x, trn_y,\n",
    "                 eval_set=(val_x, val_y),\n",
    "                 use_best_model=True,\n",
    "                 verbose=False)\n",
    "    \n",
    "    val_pred = model.predict(val_x)\n",
    "    test_pred = model.predict(test)\n",
    "    \n",
    "    return {'val':val_pred, 'test':test_pred, 'error':model.get_best_score()['validation_0']['RMSE'], 'importance':model.get_feature_importance()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold.    RMSE\n",
      "xgb model. 2.20203 (0m)\n",
      "lgb model. 2.18165 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.19184\n",
      "blend err. 2.18668\n",
      "\n",
      "2 fold.    RMSE\n",
      "xgb model. 2.60756 (0m)\n",
      "lgb model. 2.57574 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.59165\n",
      "blend err. 2.58534\n",
      "\n",
      "3 fold.    RMSE\n",
      "xgb model. 2.32793 (0m)\n",
      "lgb model. 2.29481 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.31137\n",
      "blend err. 2.30251\n",
      "\n",
      "4 fold.    RMSE\n",
      "xgb model. 2.29672 (0m)\n",
      "lgb model. 2.24911 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.27291\n",
      "blend err. 2.26502\n",
      "\n",
      "5 fold.    RMSE\n",
      "xgb model. 2.43987 (0m)\n",
      "lgb model. 2.44855 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.44421\n",
      "blend err. 2.43433\n",
      "\n",
      "6 fold.    RMSE\n",
      "xgb model. 2.33555 (0m)\n",
      "lgb model. 2.32395 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.32975\n",
      "blend err. 2.32382\n",
      "\n",
      "7 fold.    RMSE\n",
      "xgb model. 2.16296 (0m)\n",
      "lgb model. 2.14415 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.15356\n",
      "blend err. 2.14695\n",
      "\n",
      "8 fold.    RMSE\n",
      "xgb model. 2.29163 (0m)\n",
      "lgb model. 2.28621 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.28892\n",
      "blend err. 2.28290\n",
      "\n",
      "9 fold.    RMSE\n",
      "xgb model. 2.11998 (0m)\n",
      "lgb model. 2.08837 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.10417\n",
      "blend err. 2.09808\n",
      "\n",
      "10 fold.    RMSE\n",
      "xgb model. 2.35540 (0m)\n",
      "lgb model. 2.33697 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.34618\n",
      "blend err. 2.34172\n",
      "\n",
      "fianl avg   err. 2.3034559611094596\n",
      "fianl blend err. 2.3006543778546416\n"
     ]
    }
   ],
   "source": [
    "result_dict = dict()\n",
    "val_pred = np.zeros(train.shape[0])\n",
    "test_pred = np.zeros(test.shape[0])\n",
    "final_err = 0\n",
    "verbose = False\n",
    "\n",
    "for i, (trn, val) in enumerate(fold) :\n",
    "    print(i+1, \"fold.    RMSE\")\n",
    "    \n",
    "    trn_x = train.loc[trn, :]\n",
    "    trn_y = y[trn]\n",
    "    val_x = train.loc[val, :]\n",
    "    val_y = y[val]\n",
    "    \n",
    "    fold_val_pred = []\n",
    "    fold_test_pred = []\n",
    "    fold_err = []\n",
    "    \n",
    "    \n",
    "    start = datetime.now()\n",
    "    result = xgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val'])\n",
    "    fold_test_pred.append(result['test'])\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"xgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    \n",
    "    start = datetime.now()\n",
    "    result = lgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val'])\n",
    "    fold_test_pred.append(result['test'])\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"lgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    \n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    result = cat_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val'])\n",
    "    fold_test_pred.append(result['test'])\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"cat model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    \"\"\"\n",
    "    \n",
    "    val_pred[val] += np.mean(np.array(fold_val_pred), axis = 0)\n",
    "    test_pred += np.mean(np.array(fold_test_pred), axis = 0) / K\n",
    "    final_err += (sum(fold_err) / len(fold_err)) / K\n",
    "    \n",
    "    print(\"---------------------------\")\n",
    "    print(\"avg   err.\", \"{0:.5f}\".format(sum(fold_err) / len(fold_err)))\n",
    "    print(\"blend err.\", \"{0:.5f}\".format(np.sqrt(np.mean((np.mean(np.array(fold_val_pred), axis = 0) - val_y)**2))))\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "print(\"fianl avg   err.\", final_err)\n",
    "print(\"fianl blend err.\", np.sqrt(np.mean((val_pred - y)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('data/sample_submission.csv')\n",
    "df_sub = pd.DataFrame()\n",
    "df_sub['id'] = sub['id']\n",
    "df_sub['revenue'] = np.expm1(test_pred)\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_model_2(trn_X, trn_y, val_X, val_y, test, verbose):\n",
    "    \n",
    "    params = {'objective': 'reg:linear',\n",
    "              'eta': 0.1, \n",
    "              'max_depth': 3,\n",
    "              'subsample': 0.4,\n",
    "              'colsample_bytree': 0.5,\n",
    "              'eval_metrics': 'rmse',\n",
    "              'seed': SEED,\n",
    "              'silent': True}\n",
    "    \n",
    "    record = dict()\n",
    "    \n",
    "    model = xgb.train(params, xgb.DMatrix(trn_X, trn_y), 1000,\n",
    "                      [(xgb.DMatrix(trn_X, trn_y), 'train'),\n",
    "                      (xgb.DMatrix(val_X, val_y), 'valid')],\n",
    "                      verbose_eval=verbose,\n",
    "                      early_stopping_rounds=200,\n",
    "                      callbacks=[xgb.callback.record_evaluation(record)])\n",
    "    \n",
    "    best_idx = np.argmin(np.array(record['valid']['rmse']))\n",
    "    \n",
    "    val_pred = model.predict(xgb.DMatrix(val_X), ntree_limit=model.best_ntree_limit)\n",
    "    test_pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n",
    "    \n",
    "    return {'val': val_pred, 'test': test_pred, 'error': record['valid']['rmse'][best_idx], 'importance': [i for k, i in model.get_score().items()]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model_2(trn_x, trn_y, val_x, val_y, test, verbose) :\n",
    "\n",
    "    params = {'objective':'regression_l2',\n",
    "         'num_leaves' : 50,\n",
    "         'min_data_in_leaf' : 15,\n",
    "         'max_depth' : 4,\n",
    "         'learning_rate': 0.01,\n",
    "         'feature_fraction': 0.8,\n",
    "         'bagging_freq': 1,\n",
    "         'bagging_fraction': 0.8,\n",
    "         'bagging_seed': SEED,\n",
    "         'metric': 'rmse',\n",
    "         'random_state' : SEED,\n",
    "         'verbosity': -1}\n",
    "\n",
    "    record = dict()\n",
    "    model = lgb.train(params\n",
    "                      , lgb.Dataset(trn_x, trn_y)\n",
    "                      , num_boost_round = 10000\n",
    "                      , valid_sets = [lgb.Dataset(val_x, val_y)]\n",
    "                      , verbose_eval = verbose\n",
    "                      , early_stopping_rounds = 200\n",
    "                      , callbacks = [lgb.record_evaluation(record)]\n",
    "                     )\n",
    "    best_idx = np.argmin(np.array(record['valid_0']['rmse']))\n",
    "\n",
    "    val_pred = model.predict(val_x, num_iteration = model.best_iteration)\n",
    "    test_pred = model.predict(test, num_iteration = model.best_iteration)\n",
    "    \n",
    "    return {'val':val_pred, 'test':test_pred, 'error':record['valid_0']['rmse'][best_idx], 'importance':model.feature_importance('gain')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold.    RMSE\n",
      "xgb model. 2.20590 (0m)\n",
      "lgb model. 2.19485 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.20037\n",
      "blend err. 2.18922\n",
      "\n",
      "2 fold.    RMSE\n",
      "xgb model. 2.61319 (0m)\n",
      "lgb model. 2.56509 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.58914\n",
      "blend err. 2.56123\n",
      "\n",
      "3 fold.    RMSE\n",
      "xgb model. 2.33092 (0m)\n",
      "lgb model. 2.29304 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.31198\n",
      "blend err. 2.29923\n",
      "\n",
      "4 fold.    RMSE\n",
      "xgb model. 2.31830 (0m)\n",
      "lgb model. 2.24868 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.28349\n",
      "blend err. 2.26996\n",
      "\n",
      "5 fold.    RMSE\n",
      "xgb model. 2.40779 (0m)\n",
      "lgb model. 2.42948 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.41863\n",
      "blend err. 2.40144\n",
      "\n",
      "6 fold.    RMSE\n",
      "xgb model. 2.37108 (0m)\n",
      "lgb model. 2.30686 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.33897\n",
      "blend err. 2.32200\n",
      "\n",
      "7 fold.    RMSE\n",
      "xgb model. 2.18863 (0m)\n",
      "lgb model. 2.14278 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.16571\n",
      "blend err. 2.14810\n",
      "\n",
      "8 fold.    RMSE\n",
      "xgb model. 2.36428 (0m)\n",
      "lgb model. 2.29333 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.32880\n",
      "blend err. 2.31397\n",
      "\n",
      "9 fold.    RMSE\n",
      "xgb model. 2.19199 (0m)\n",
      "lgb model. 2.09234 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.14217\n",
      "blend err. 2.12887\n",
      "\n",
      "10 fold.    RMSE\n",
      "xgb model. 2.37581 (0m)\n",
      "lgb model. 2.34995 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.36288\n",
      "blend err. 2.34794\n",
      "\n",
      "fianl avg   err. 2.31421399890115\n",
      "fianl blend err. 2.3013930401165923\n"
     ]
    }
   ],
   "source": [
    "result_dict_2 = dict()\n",
    "val_pred_2 = np.zeros(train.shape[0])\n",
    "test_pred_2 = np.zeros(test.shape[0])\n",
    "final_err_2 = 0\n",
    "verbose = False\n",
    "\n",
    "for i, (trn, val) in enumerate(fold) :\n",
    "    print(i+1, \"fold.    RMSE\")\n",
    "    \n",
    "    trn_x = train.loc[trn, :]\n",
    "    trn_y = y[trn]\n",
    "    val_x = train.loc[val, :]\n",
    "    val_y = y[val]\n",
    "    \n",
    "    fold_val_pred = []\n",
    "    fold_test_pred = []\n",
    "    fold_err = []\n",
    "    \n",
    "    \n",
    "    start = datetime.now()\n",
    "    result = xgb_model_2(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val'])\n",
    "    fold_test_pred.append(result['test'])\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"xgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    \n",
    "    start = datetime.now()\n",
    "    result = lgb_model_2(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val'])\n",
    "    fold_test_pred.append(result['test'])\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"lgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    \n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    result = cat_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val'])\n",
    "    fold_test_pred.append(result['test'])\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"cat model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    \"\"\"\n",
    "    \n",
    "    val_pred_2[val] += np.mean(np.array(fold_val_pred), axis = 0)\n",
    "    test_pred_2 += np.mean(np.array(fold_test_pred), axis = 0) / K\n",
    "    final_err_2 += (sum(fold_err) / len(fold_err)) / K\n",
    "    \n",
    "    print(\"---------------------------\")\n",
    "    print(\"avg   err.\", \"{0:.5f}\".format(sum(fold_err) / len(fold_err)))\n",
    "    print(\"blend err.\", \"{0:.5f}\".format(np.sqrt(np.mean((np.mean(np.array(fold_val_pred), axis = 0) - val_y)**2))))\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "print(\"fianl avg   err.\", final_err_2)\n",
    "print(\"fianl blend err.\", np.sqrt(np.mean((val_pred_2 - y)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('data/sample_submission.csv')\n",
    "df_sub = pd.DataFrame()\n",
    "df_sub['id'] = sub['id']\n",
    "df_sub['revenue'] = np.expm1(test_pred_2)\n",
    "df_sub.to_csv(\"submission_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.read_csv('submission.csv')\n",
    "sub2 = pd.read_csv('submission_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3001</td>\n",
       "      <td>6.415744e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3002</td>\n",
       "      <td>2.414149e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3003</td>\n",
       "      <td>7.401852e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3004</td>\n",
       "      <td>7.022518e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3005</td>\n",
       "      <td>1.025829e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id       revenue\n",
       "0  3001  6.415744e+06\n",
       "1  3002  2.414149e+06\n",
       "2  3003  7.401852e+06\n",
       "3  3004  7.022518e+06\n",
       "4  3005  1.025829e+06"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_sub = sub1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_sub['revenue'] = .5*sub1['revenue'] + .5*sub2['revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_sub.to_csv('fin_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
