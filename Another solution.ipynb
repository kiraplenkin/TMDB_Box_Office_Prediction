{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "import numpy as np\n",
    "import ast\n",
    "import gc\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_columns = ['belongs_to_collection', 'genres', 'production_companies',\n",
    "                'production_countries', 'spoken_languages', 'Keywords',\n",
    "                'cast', 'crew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_dict(df):\n",
    "    for column in dict_columns:\n",
    "        df[column] = df[column].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = text_to_dict(train)\n",
    "test = text_to_dict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collection\n",
    "\n",
    "train['collection_name'] = train['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\n",
    "train['has_collection'] = train['belongs_to_collection'].apply(lambda x: len(x) if x != {} else 0)\n",
    "\n",
    "test['collection_name'] = test['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\n",
    "test['has_collection'] = test['belongs_to_collection'].apply(lambda x: len(x) if x != {} else 0)\n",
    "\n",
    "train = train.drop(['belongs_to_collection'], axis=1)\n",
    "test = test.drop(['belongs_to_collection'], axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Genres\n",
    "\n",
    "list_of_genres = list(train['genres'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n",
    "\n",
    "train['num_genres'] = train['genres'].apply(lambda x: len(x) if x != {} else 0)\n",
    "train['all_genres'] = train['genres'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n",
    "top_genres = [m[0] for m in Counter([i for j in list_of_genres for i in j]).most_common(10)]\n",
    "for g in top_genres:\n",
    "    train['genre_' + g] = train['all_genres'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "test['num_genres'] = test['genres'].apply(lambda x: len(x) if x != {} else 0)\n",
    "test['all_genres'] = test['genres'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n",
    "for g in top_genres:\n",
    "    test['genre_' + g] = test['all_genres'].apply(lambda x: 1 if g in x else 0)    \n",
    "    \n",
    "train = train.drop(['genres'], axis=1)\n",
    "test = test.drop(['genres'], axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homepage\n",
    "\n",
    "train['homepage'] = train['homepage'].fillna(0)\n",
    "train['homepage'] = train['homepage'].apply(lambda x: 0 if x==0 else 1)\n",
    "\n",
    "test['homepage'] = test['homepage'].fillna(0)\n",
    "test['homepage'] = test['homepage'].apply(lambda x: 0 if x==0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Production companies\n",
    "\n",
    "list_of_companies = list(train['production_companies'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n",
    "\n",
    "train['num_companies'] = train['production_companies'].apply(lambda x: len(x) if x != {} else 0)\n",
    "train['all_production_companies'] = train['production_companies'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n",
    "top_companies = [m[0] for m in Counter([i for j in list_of_companies for i in j]).most_common(20)]\n",
    "for g in top_companies:\n",
    "    train['production_company_' + g] = train['all_production_companies'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "test['num_companies'] = test['production_companies'].apply(lambda x: len(x) if x != {} else 0)\n",
    "test['all_production_companies'] = test['production_companies'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n",
    "for g in top_companies:\n",
    "    test['production_company_' + g] = test['all_production_companies'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "train = train.drop(['production_companies', 'all_production_companies'], axis=1)\n",
    "test = test.drop(['production_companies', 'all_production_companies'], axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Production Countries\n",
    "\n",
    "list_of_countries = list(train['production_countries'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n",
    "\n",
    "train['num_countries'] = train['production_countries'].apply(lambda x: len(x) if x != {} else 0)\n",
    "train['all_countries'] = train['production_countries'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n",
    "top_countries = [m[0] for m in Counter([i for j in list_of_countries for i in j]).most_common(25)]\n",
    "for g in top_countries:\n",
    "    train['production_country_' + g] = train['all_countries'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "test['num_countries'] = test['production_countries'].apply(lambda x: len(x) if x != {} else 0)\n",
    "test['all_countries'] = test['production_countries'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n",
    "for g in top_countries:\n",
    "    test['production_country_' + g] = test['all_countries'].apply(lambda x: 1 if g in x else 0)\n",
    "\n",
    "train = train.drop(['production_countries', 'all_countries'], axis=1)\n",
    "test = test.drop(['production_countries', 'all_countries'], axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# languages\n",
    "\n",
    "list_of_languages = list(train['spoken_languages'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n",
    "\n",
    "train['num_languages'] = train['spoken_languages'].apply(lambda x: len(x) if x != {} else 0)\n",
    "train['all_languages'] = train['spoken_languages'].apply(lambda x: ' '.join(sorted([i['iso_639_1'] for i in x])) if x != {} else {})\n",
    "top_languages = [m[0] for m in Counter([i for j in list_of_languages for i in j]).most_common(20)]\n",
    "for g in top_languages:\n",
    "    train['language_' + g] = train['all_languages'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "test['num_languages'] = test['spoken_languages'].apply(lambda x: len(x) if x != {} else 0)\n",
    "test['all_languages'] = test['spoken_languages'].apply(lambda x: ' '.join(sorted([i['iso_639_1'] for i in x])) if x != {} else {})\n",
    "for g in top_languages:\n",
    "    test['language_' + g] = test['all_languages'].apply(lambda x: 1 if g in x else 0)\n",
    "\n",
    "train = train.drop(['spoken_languages', 'all_languages'], axis=1)\n",
    "test = test.drop(['spoken_languages', 'all_languages'], axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keywords\n",
    "\n",
    "list_of_keywords = list(train['Keywords'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n",
    "\n",
    "train['num_Keywords'] = train['Keywords'].apply(lambda x: len(x) if x != {} else 0)\n",
    "train['all_Keywords'] = train['Keywords'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n",
    "top_keywords = [m[0] for m in Counter([i for j in list_of_keywords for i in j]).most_common(20)]\n",
    "for g in top_keywords:\n",
    "    train['keyword_' + g] = train['all_Keywords'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "test['num_Keywords'] = test['Keywords'].apply(lambda x: len(x) if x != {} else 0)\n",
    "test['all_Keywords'] = test['Keywords'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n",
    "for g in top_keywords:\n",
    "    test['keyword_' + g] = test['all_Keywords'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "train = train.drop(['Keywords', 'all_Keywords'], axis=1)\n",
    "test = test.drop(['Keywords', 'all_Keywords'], axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cast\n",
    "\n",
    "list_of_cast_names = list(train['cast'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n",
    "list_of_cast_gender = list(train['cast'].apply(lambda x: [i['gender'] for i in x] if x != {} else []).values)\n",
    "list_of_cast_characters = list(train['cast'].apply(lambda x: [i['character'] for i in x] if x != {} else []).values)\n",
    "\n",
    "train['num_cast'] = train['cast'].apply(lambda x: len(x) if x != {} else 0)\n",
    "top_cast_names = [m[0] for m in Counter([i for j in list_of_cast_names for i in j]).most_common(15)]\n",
    "for g in top_cast_names:\n",
    "    train['cast_name_' + g] = train['cast'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "train['gender_0'] = train['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\n",
    "train['gender_1'] = train['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\n",
    "train['gender_2'] = train['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n",
    "\n",
    "top_cast_characters = [m[0] for m in Counter([i for j in list_of_cast_characters for i in j]).most_common(10)]\n",
    "for g in top_cast_characters:\n",
    "    train['cast_character_' + g] = train['cast'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "test['num_cast'] = test['cast'].apply(lambda x: len(x) if x != {} else 0)\n",
    "for g in top_cast_names:\n",
    "    test['cast_name_' + g] = test['cast'].apply(lambda x: 1 if g in x else 0)\n",
    "    \n",
    "test['gender_0'] = test['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\n",
    "test['gender_1'] = test['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\n",
    "test['gender_2'] = test['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n",
    "\n",
    "for g in top_cast_characters:\n",
    "    test['cast_character_' + g] = test['cast'].apply(lambda x: 1 if g in x else 0)\n",
    "\n",
    "train = train.drop(['cast'], axis=1)\n",
    "test = test.drop(['cast'], axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crew\n",
    "\n",
    "list_of_crew_names = list(train['crew'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n",
    "list_of_crew_jobs = list(train['crew'].apply(lambda x: [i['job'] for i in x] if x != {} else []).values)\n",
    "list_of_crew_genders = list(train['crew'].apply(lambda x: [i['gender'] for i in x] if x != {} else []).values)\n",
    "list_of_crew_departments = list(train['crew'].apply(lambda x: [i['department'] for i in x] if x != {} else []).values)\n",
    "\n",
    "train['num_crew'] = train['crew'].apply(lambda x: len(x) if x != {} else 0)\n",
    "top_crew_names = [m[0] for m in Counter([i for j in list_of_crew_names for i in j]).most_common(15)]\n",
    "for g in top_crew_names:\n",
    "    train['crew_name_' + g] = train['crew'].apply(lambda x: 1 if g in x else 0)\n",
    "\n",
    "train['genders_0'] = train['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\n",
    "train['genders_1'] = train['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\n",
    "train['genders_2'] = train['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n",
    "\n",
    "top_cast_characters = [m[0] for m in Counter([i for j in list_of_cast_characters for i in j]).most_common(15)]\n",
    "for g in top_cast_characters:\n",
    "    train['crew_character_' + g] = train['crew'].apply(lambda x: 1 if g in x else 0)\n",
    "\n",
    "top_crew_jobs = [m[0] for m in Counter([i for j in list_of_crew_jobs for i in j]).most_common(15)]\n",
    "for j in top_crew_jobs:\n",
    "    train['jobs_' + j] = train['crew'].apply(lambda x: sum([1 for i in x if i['job'] == j]))\n",
    "\n",
    "top_crew_departments = [m[0] for m in Counter([i for j in list_of_crew_departments for i in j]).most_common(15)]\n",
    "for j in top_crew_departments:\n",
    "    train['departments_' + j] = train['crew'].apply(lambda x: sum([1 for i in x if i['department'] == j])) \n",
    "    \n",
    "test['num_crew'] = test['crew'].apply(lambda x: len(x) if x != {} else 0)\n",
    "for g in top_crew_names:\n",
    "    test['crew_name_' + g] = test['crew'].apply(lambda x: 1 if g in x else 0)\n",
    "\n",
    "test['genders_0'] = test['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\n",
    "test['genders_1'] = test['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\n",
    "test['genders_2'] = test['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n",
    "\n",
    "for g in top_cast_characters:\n",
    "    test['crew_character_' + g] = test['crew'].apply(lambda x: 1 if g in x else 0)\n",
    "\n",
    "for j in top_crew_jobs:\n",
    "    test['jobs_' + j] = test['crew'].apply(lambda x: sum([1 for i in x if i['job'] == j]))\n",
    "\n",
    "for j in top_crew_departments:\n",
    "    test['departments_' + j] = test['crew'].apply(lambda x: sum([1 for i in x if i['department'] == j])) \n",
    "\n",
    "train = train.drop(['crew'], axis=1)\n",
    "test = test.drop(['crew'], axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['log_revenue'] = np.log1p(train['revenue'])\n",
    "\n",
    "train['log_budget'] = np.log1p(train['budget'])\n",
    "test['log_budget'] = np.log1p(test['budget'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lang = ['en', 'fr', 'ru', 'es', 'hi', 'ja', 'it', 'ko', 'cn', 'zh', 'de', 'ta']\n",
    "\n",
    "train['original_language'] = train['original_language'].apply(lambda x: x if x in list_of_lang else 'Other')\n",
    "test['original_language'] = test['original_language'].apply(lambda x: x if x in list_of_lang else 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_status = ['Released', 'Post Production', 'Rumored']\n",
    "\n",
    "train['status'] = train['status'].apply(lambda x: x if x in list_of_status else 'Other')\n",
    "test['status'] = test['status'].apply(lambda x: x if x in list_of_status else 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['original_language', 'collection_name', 'all_genres', 'status']:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(train[col].fillna('')) + list(test[col].fillna('')))\n",
    "    train[col] = le.transform(train[col].fillna('').astype(str))\n",
    "    test[col] = le.transform(test[col].fillna('').astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_date(x):\n",
    "\n",
    "    year = x.split('/')[2]\n",
    "    if int(year) <= 19:\n",
    "        return x[:-2] + '20' + year\n",
    "    else:\n",
    "        return x[:-2] + '19' + year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['release_date'].isnull() == True, 'release_date'] = '01/01/98'\n",
    "\n",
    "train['release_date'] = train['release_date'].apply(lambda x: fix_date(x))\n",
    "test['release_date'] = test['release_date'].apply(lambda x: fix_date(x))\n",
    "\n",
    "train['release_date'] = pd.to_datetime(train['release_date'])\n",
    "test['release_date'] = pd.to_datetime(test['release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date(df):\n",
    "    \n",
    "    date_parts = ['year', 'weekday', 'month', 'weekofyear', 'day', 'quarter']\n",
    "    for part in date_parts:\n",
    "        part_col = 'release_date' + \"_\" + part\n",
    "        df[part_col] = getattr(df['release_date'].dt, part).astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = process_date(train)\n",
    "test = process_date(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['title', 'tagline', 'overview', 'original_title']:\n",
    "    train['len_' + col] = train[col].fillna('').apply(lambda x: len(str(x)))\n",
    "    train['words_' + col] = train[col].fillna('').apply(lambda x: len(str(x.split(' '))))\n",
    "    train = train.drop(col, axis=1)\n",
    "    \n",
    "    test['len_' + col] = test[col].fillna('').apply(lambda x: len(str(x)))\n",
    "    test['words_' + col] = test[col].fillna('').apply(lambda x: len(str(x.split(' '))))\n",
    "    test = test.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train['log_revenue']\n",
    "train = train.drop(['id', 'release_date', 'revenue', 'log_revenue', 'imdb_id', 'poster_path'], axis=1)\n",
    "test = test.drop(['id', 'release_date', 'imdb_id', 'poster_path'], axis=1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['budget_runtime_ratio'] = train['log_budget'] / train['runtime']\n",
    "test['budget_runtime_ratio'] = test['log_budget'] / test['runtime']\n",
    "\n",
    "train['budget_popularity_ratio'] = train['log_budget'] / train['popularity']\n",
    "test['budget_popularity_ratio'] = test['log_budget'] / test['popularity']\n",
    "\n",
    "train['releaseYear_popularity_ratio'] = train['release_date_year'] / train['popularity']\n",
    "test['releaseYear_popularity_ratio'] = test['release_date_year'] / test['popularity']\n",
    "\n",
    "train['releaseYear_popularity_ratio2'] = train['popularity'] / train['release_date_year']\n",
    "test['releaseYear_popularity_ratio2'] = test['popularity'] / test['release_date_year']\n",
    "\n",
    "\n",
    "train['meanRuntimeByYear'] = train.groupby('release_date_year')['runtime'].aggregate('mean')\n",
    "test['meanRuntimeByYear'] = test.groupby('release_date_year')['runtime'].aggregate('mean')\n",
    "\n",
    "train['meanPopularityByYear'] = train.groupby('release_date_year')['popularity'].aggregate('mean')\n",
    "test['meanPopularityByYear'] = test.groupby('release_date_year')['popularity'].aggregate('mean')\n",
    "\n",
    "train['meanBudgetByYear'] = train.groupby('release_date_year')['log_budget'].aggregate('mean')\n",
    "test['meanBudgetByYear'] = test.groupby('release_date_year')['log_budget'].aggregate('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 10\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, X_test, y, params=None, folds=folds, model_type='lgb', plot_feature_importance=False, model=None):\n",
    "\n",
    "    oof = np.zeros(X.shape[0])\n",
    "    prediction = np.zeros(X_test.shape[0])\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "        print('Fold', fold_n, 'started at', time.ctime())\n",
    "        if model_type == 'sklearn':\n",
    "            X_train, X_valid = X[train_index], X[valid_index]\n",
    "        else:\n",
    "            X_train, X_valid = X.values[train_index], X.values[valid_index]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            model = lgb.LGBMRegressor(**params, n_estimators = 20000, nthread = 4, n_jobs = -1)\n",
    "            model.fit(X_train, y_train, \n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='rmse',\n",
    "                    verbose=1000, early_stopping_rounds=200)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=30000, evals=watchlist, early_stopping_rounds=200, verbose_eval=500, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test.values), ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = mean_squared_error(y_valid, y_pred_valid)\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostRegressor(iterations=20000,  eval_metric='RMSE', **params)\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        scores.append(mean_squared_error(y_valid, y_pred_valid) ** 0.5)\n",
    "        \n",
    "        prediction += y_pred    \n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = X.columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_fold\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        feature_importance[\"importance\"] /= n_fold\n",
    "        if plot_feature_importance:\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "        \n",
    "            return oof, prediction, feature_importance\n",
    "        return oof, prediction\n",
    "    \n",
    "    else:\n",
    "        return oof, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sat May 25 12:54:27 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[434]\ttraining's rmse: 1.55084\tvalid_1's rmse: 2.08688\n",
      "Fold 1 started at Sat May 25 12:54:29 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.30121\tvalid_1's rmse: 1.85964\n",
      "Early stopping, best iteration is:\n",
      "[1275]\ttraining's rmse: 1.19034\tvalid_1's rmse: 1.85335\n",
      "Fold 2 started at Sat May 25 12:54:33 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.30045\tvalid_1's rmse: 1.88463\n",
      "[2000]\ttraining's rmse: 0.965538\tvalid_1's rmse: 1.87021\n",
      "Early stopping, best iteration is:\n",
      "[1986]\ttraining's rmse: 0.969722\tvalid_1's rmse: 1.86949\n",
      "Fold 3 started at Sat May 25 12:54:38 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.28524\tvalid_1's rmse: 1.91361\n",
      "Early stopping, best iteration is:\n",
      "[878]\ttraining's rmse: 1.33736\tvalid_1's rmse: 1.90871\n",
      "Fold 4 started at Sat May 25 12:54:41 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.26942\tvalid_1's rmse: 2.17884\n",
      "Early stopping, best iteration is:\n",
      "[1454]\ttraining's rmse: 1.09972\tvalid_1's rmse: 2.17403\n",
      "Fold 5 started at Sat May 25 12:54:45 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.30264\tvalid_1's rmse: 1.83569\n",
      "Early stopping, best iteration is:\n",
      "[877]\ttraining's rmse: 1.35368\tvalid_1's rmse: 1.83061\n",
      "Fold 6 started at Sat May 25 12:54:47 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[568]\ttraining's rmse: 1.43688\tvalid_1's rmse: 2.44662\n",
      "Fold 7 started at Sat May 25 12:54:49 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.27051\tvalid_1's rmse: 2.24458\n",
      "Early stopping, best iteration is:\n",
      "[1090]\ttraining's rmse: 1.23475\tvalid_1's rmse: 2.24289\n",
      "Fold 8 started at Sat May 25 12:54:52 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[357]\ttraining's rmse: 1.61595\tvalid_1's rmse: 2.2968\n",
      "Fold 9 started at Sat May 25 12:54:54 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.26307\tvalid_1's rmse: 2.04441\n",
      "Early stopping, best iteration is:\n",
      "[1098]\ttraining's rmse: 1.22363\tvalid_1's rmse: 2.04319\n",
      "CV mean score: 2.0753, std: 0.2013.\n"
     ]
    }
   ],
   "source": [
    "params = {'num_leaves': 30,\n",
    "         'min_data_in_leaf': 10,\n",
    "         'objective': 'regression',\n",
    "         'max_depth': 5,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.2,\n",
    "         \"verbosity\": -1}\n",
    "oof_lgb, prediction_lgb, = train_model(train, test, y, params=params, model_type='lgb', plot_feature_importance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_features(df):\n",
    "    df['budget_to_popularity'] = df['budget'] / df['popularity']\n",
    "    df['budget_to_runtime'] = df['budget'] / df['runtime']\n",
    "    \n",
    "    # some features from https://www.kaggle.com/somang1418/happy-valentines-day-and-keep-kaggling-3\n",
    "    df['_budget_year_ratio'] = df['budget'] / (df['release_date_year'] * df['release_date_year'])\n",
    "    df['_releaseYear_popularity_ratio'] = df['release_date_year'] / df['popularity']\n",
    "    df['_releaseYear_popularity_ratio2'] = df['popularity'] / df['release_date_year']\n",
    "    \n",
    "    df['runtime_to_mean_year'] = df['runtime'] / df.groupby(\"release_date_year\")[\"runtime\"].transform('mean')\n",
    "    df['popularity_to_mean_year'] = df['popularity'] / df.groupby(\"release_date_year\")[\"popularity\"].transform('mean')\n",
    "    df['budget_to_mean_year'] = df['budget'] / df.groupby(\"release_date_year\")[\"budget\"].transform('mean')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_features(train)\n",
    "X_test = new_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sat May 25 12:56:56 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.24313\tvalid_1's rmse: 2.05893\n",
      "Early stopping, best iteration is:\n",
      "[1084]\ttraining's rmse: 1.20801\tvalid_1's rmse: 2.05614\n",
      "Fold 1 started at Sat May 25 12:56:59 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.27244\tvalid_1's rmse: 1.8683\n",
      "Early stopping, best iteration is:\n",
      "[1352]\ttraining's rmse: 1.12702\tvalid_1's rmse: 1.86274\n",
      "Fold 2 started at Sat May 25 12:57:02 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.27507\tvalid_1's rmse: 1.88514\n",
      "Early stopping, best iteration is:\n",
      "[1453]\ttraining's rmse: 1.10225\tvalid_1's rmse: 1.8713\n",
      "Fold 3 started at Sat May 25 12:57:06 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.26153\tvalid_1's rmse: 1.88034\n",
      "Early stopping, best iteration is:\n",
      "[969]\ttraining's rmse: 1.27348\tvalid_1's rmse: 1.8788\n",
      "Fold 4 started at Sat May 25 12:57:08 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.25307\tvalid_1's rmse: 2.14138\n",
      "Early stopping, best iteration is:\n",
      "[1043]\ttraining's rmse: 1.23413\tvalid_1's rmse: 2.13869\n",
      "Fold 5 started at Sat May 25 12:57:11 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[701]\ttraining's rmse: 1.4192\tvalid_1's rmse: 1.87015\n",
      "Fold 6 started at Sat May 25 12:57:14 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.22561\tvalid_1's rmse: 2.42134\n",
      "Early stopping, best iteration is:\n",
      "[999]\ttraining's rmse: 1.22599\tvalid_1's rmse: 2.42119\n",
      "Fold 7 started at Sat May 25 12:57:16 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.23766\tvalid_1's rmse: 2.24748\n",
      "Early stopping, best iteration is:\n",
      "[1092]\ttraining's rmse: 1.19908\tvalid_1's rmse: 2.24638\n",
      "Fold 8 started at Sat May 25 12:57:19 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[463]\ttraining's rmse: 1.51896\tvalid_1's rmse: 2.27326\n",
      "Fold 9 started at Sat May 25 12:57:21 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.23659\tvalid_1's rmse: 2.04269\n",
      "Early stopping, best iteration is:\n",
      "[1216]\ttraining's rmse: 1.14808\tvalid_1's rmse: 2.04059\n",
      "CV mean score: 2.0659, std: 0.1898.\n"
     ]
    }
   ],
   "source": [
    "oof_lgb, prediction_lgb, = train_model(X, X_test, y, params=params, model_type='lgb', plot_feature_importance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_cols_interaction(df):\n",
    "    df['budget_to_year'] = df['budget'] / df['release_date_year']\n",
    "    df['budget_to_mean_year_to_year'] = df['budget_to_mean_year'] / df['release_date_year']\n",
    "    df['popularity_to_mean_year_to_log_budget'] = df['popularity_to_mean_year'] / df['log_budget']\n",
    "    df['year_to_log_budget'] = df['release_date_year'] / df['log_budget']\n",
    "    df['budget_to_runtime_to_year'] = df['budget_to_runtime'] / df['release_date_year']\n",
    "    df['all_genres_to_popularity_to_mean_year'] = df['all_genres'] / df['popularity_to_mean_year']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = top_cols_interaction(X)\n",
    "X_test = top_cols_interaction(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.replace([np.inf, -np.inf], 0).fillna(0)\n",
    "X_test = X_test.replace([np.inf, -np.inf], 0).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAdditionalFeatures = pd.read_csv('data/TrainAdditionalFeatures.csv.xls')\n",
    "testAdditionalFeatures = pd.read_csv('data/TestAdditionalFeatures.csv.xls')\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "X['imdb_id'] = train['imdb_id']\n",
    "X_test['imdb_id'] = test['imdb_id']\n",
    "del train, test\n",
    "\n",
    "X = pd.merge(X, trainAdditionalFeatures, how='left', on=['imdb_id'])\n",
    "X_test = pd.merge(X_test, testAdditionalFeatures, how='left', on=['imdb_id'])\n",
    "\n",
    "X = X.drop(['imdb_id'], axis=1)\n",
    "X_test = X_test.drop(['imdb_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sat May 25 13:05:52 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[699]\ttraining's rmse: 1.06241\tvalid_1's rmse: 1.99571\n",
      "Fold 1 started at Sat May 25 13:05:55 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[654]\ttraining's rmse: 1.12796\tvalid_1's rmse: 1.83412\n",
      "Fold 2 started at Sat May 25 13:05:58 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 0.899502\tvalid_1's rmse: 1.80697\n",
      "Early stopping, best iteration is:\n",
      "[1073]\ttraining's rmse: 0.860726\tvalid_1's rmse: 1.80482\n",
      "Fold 3 started at Sat May 25 13:06:03 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[693]\ttraining's rmse: 1.08194\tvalid_1's rmse: 1.7774\n",
      "Fold 4 started at Sat May 25 13:06:06 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 0.872187\tvalid_1's rmse: 1.99703\n",
      "Early stopping, best iteration is:\n",
      "[1131]\ttraining's rmse: 0.805735\tvalid_1's rmse: 1.99508\n",
      "Fold 5 started at Sat May 25 13:06:11 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[504]\ttraining's rmse: 1.23834\tvalid_1's rmse: 1.79582\n",
      "Fold 6 started at Sat May 25 13:06:13 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[611]\ttraining's rmse: 1.12311\tvalid_1's rmse: 2.24219\n",
      "Fold 7 started at Sat May 25 13:06:16 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[661]\ttraining's rmse: 1.08879\tvalid_1's rmse: 2.15883\n",
      "Fold 8 started at Sat May 25 13:06:19 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[675]\ttraining's rmse: 1.08032\tvalid_1's rmse: 2.06772\n",
      "Fold 9 started at Sat May 25 13:06:22 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[224]\ttraining's rmse: 1.59035\tvalid_1's rmse: 2.00682\n",
      "CV mean score: 1.9679, std: 0.1533.\n"
     ]
    }
   ],
   "source": [
    "params = {'num_leaves': 30,\n",
    "         'min_data_in_leaf': 20,\n",
    "         'objective': 'regression',\n",
    "         'max_depth': 9,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.2,\n",
    "         \"verbosity\": -1}\n",
    "oof_lgb, prediction_lgb, = train_model(X, X_test, y, params=params, model_type='lgb', plot_feature_importance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sat May 25 13:07:05 2019\n",
      "[0]\ttrain-rmse:15.5784\tvalid_data-rmse:15.8741\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttrain-rmse:0.920344\tvalid_data-rmse:1.95129\n",
      "[1000]\ttrain-rmse:0.549238\tvalid_data-rmse:1.93504\n",
      "Stopping. Best iteration:\n",
      "[1200]\ttrain-rmse:0.449318\tvalid_data-rmse:1.93223\n",
      "\n",
      "Fold 1 started at Sat May 25 13:07:24 2019\n",
      "[0]\ttrain-rmse:15.6063\tvalid_data-rmse:15.6201\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttrain-rmse:0.927478\tvalid_data-rmse:1.83148\n",
      "[1000]\ttrain-rmse:0.556894\tvalid_data-rmse:1.79979\n",
      "Stopping. Best iteration:\n",
      "[1192]\ttrain-rmse:0.459802\tvalid_data-rmse:1.79517\n",
      "\n",
      "Fold 2 started at Sat May 25 13:07:43 2019\n",
      "[0]\ttrain-rmse:15.5967\tvalid_data-rmse:15.7093\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttrain-rmse:0.941581\tvalid_data-rmse:1.79893\n",
      "[1000]\ttrain-rmse:0.560481\tvalid_data-rmse:1.77605\n",
      "[1500]\ttrain-rmse:0.338126\tvalid_data-rmse:1.77178\n",
      "Stopping. Best iteration:\n",
      "[1333]\ttrain-rmse:0.400279\tvalid_data-rmse:1.77063\n",
      "\n",
      "Fold 3 started at Sat May 25 13:08:05 2019\n",
      "[0]\ttrain-rmse:15.6269\tvalid_data-rmse:15.4328\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttrain-rmse:0.944914\tvalid_data-rmse:1.79137\n",
      "Stopping. Best iteration:\n",
      "[788]\ttrain-rmse:0.697622\tvalid_data-rmse:1.77166\n",
      "\n",
      "Fold 4 started at Sat May 25 13:08:19 2019\n",
      "[0]\ttrain-rmse:15.6047\tvalid_data-rmse:15.6369\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttrain-rmse:0.929903\tvalid_data-rmse:2.00895\n",
      "[1000]\ttrain-rmse:0.556984\tvalid_data-rmse:1.99629\n",
      "Stopping. Best iteration:\n",
      "[1117]\ttrain-rmse:0.49732\tvalid_data-rmse:1.99536\n",
      "\n",
      "Fold 5 started at Sat May 25 13:08:37 2019\n",
      "[0]\ttrain-rmse:15.6142\tvalid_data-rmse:15.5513\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttrain-rmse:0.957759\tvalid_data-rmse:1.74214\n",
      "[1000]\ttrain-rmse:0.574447\tvalid_data-rmse:1.73525\n",
      "Stopping. Best iteration:\n",
      "[947]\ttrain-rmse:0.606226\tvalid_data-rmse:1.7327\n",
      "\n",
      "Fold 6 started at Sat May 25 13:08:51 2019\n",
      "[0]\ttrain-rmse:15.604\tvalid_data-rmse:15.6387\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttrain-rmse:0.913619\tvalid_data-rmse:2.25189\n",
      "Stopping. Best iteration:\n",
      "[619]\ttrain-rmse:0.793321\tvalid_data-rmse:2.24835\n",
      "\n",
      "Fold 7 started at Sat May 25 13:09:02 2019\n",
      "[0]\ttrain-rmse:15.6337\tvalid_data-rmse:15.3739\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttrain-rmse:0.922839\tvalid_data-rmse:2.12562\n",
      "[1000]\ttrain-rmse:0.55346\tvalid_data-rmse:2.1161\n",
      "Stopping. Best iteration:\n",
      "[1220]\ttrain-rmse:0.448909\tvalid_data-rmse:2.11365\n",
      "\n",
      "Fold 8 started at Sat May 25 13:09:20 2019\n",
      "[0]\ttrain-rmse:15.6194\tvalid_data-rmse:15.5075\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttrain-rmse:0.934895\tvalid_data-rmse:2.05317\n",
      "Stopping. Best iteration:\n",
      "[566]\ttrain-rmse:0.866548\tvalid_data-rmse:2.05001\n",
      "\n",
      "Fold 9 started at Sat May 25 13:09:30 2019\n",
      "[0]\ttrain-rmse:15.5934\tvalid_data-rmse:15.7349\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttrain-rmse:0.91007\tvalid_data-rmse:2.07705\n",
      "Stopping. Best iteration:\n",
      "[739]\ttrain-rmse:0.713399\tvalid_data-rmse:2.05963\n",
      "\n",
      "CV mean score: 1.9469, std: 0.1659.\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {'eta': 0.01,\n",
    "              'objective': 'reg:linear',\n",
    "              'max_depth': 7,\n",
    "              'subsample': 0.8,\n",
    "              'colsample_bytree': 0.8,\n",
    "              'eval_metric': 'rmse',\n",
    "              'seed': 11,\n",
    "              'silent': True}\n",
    "oof_xgb, prediction_xgb = train_model(X, X_test, y, params=xgb_params, model_type='xgb', plot_feature_importance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sat May 25 13:12:08 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Sat May 25 13:16:45 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 started at Sat May 25 13:19:15 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 started at Sat May 25 13:24:57 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 started at Sat May 25 13:26:57 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 started at Sat May 25 13:29:06 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6 started at Sat May 25 13:32:32 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7 started at Sat May 25 13:35:49 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8 started at Sat May 25 13:36:46 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9 started at Sat May 25 13:38:20 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 1.9843, std: 0.2036.\n"
     ]
    }
   ],
   "source": [
    "cat_params = {'learning_rate': 0.002,\n",
    "              'depth': 5,\n",
    "              'l2_leaf_reg': 10,\n",
    "              # 'bootstrap_type': 'Bernoulli',\n",
    "              'colsample_bylevel': 0.8,\n",
    "              'bagging_temperature': 0.2,\n",
    "              'metric_period': 500,\n",
    "              'od_type': 'Iter',\n",
    "              'od_wait': 100,\n",
    "              'random_seed': 11,\n",
    "              'allow_writing_files': False}\n",
    "oof_cat, prediction_cat = train_model(X, X_test, y, params=cat_params, model_type='cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sat May 25 13:42:15 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.29934\tvalid_1's rmse: 1.99249\n",
      "Early stopping, best iteration is:\n",
      "[1234]\ttraining's rmse: 1.20994\tvalid_1's rmse: 1.99047\n",
      "Fold 1 started at Sat May 25 13:42:18 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.31271\tvalid_1's rmse: 1.80402\n",
      "Early stopping, best iteration is:\n",
      "[1060]\ttraining's rmse: 1.28898\tvalid_1's rmse: 1.80092\n",
      "Fold 2 started at Sat May 25 13:42:20 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[709]\ttraining's rmse: 1.44033\tvalid_1's rmse: 1.81862\n",
      "Fold 3 started at Sat May 25 13:42:23 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[680]\ttraining's rmse: 1.44691\tvalid_1's rmse: 1.77824\n",
      "Fold 4 started at Sat May 25 13:42:25 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.29266\tvalid_1's rmse: 1.9924\n",
      "Early stopping, best iteration is:\n",
      "[1334]\ttraining's rmse: 1.1674\tvalid_1's rmse: 1.98933\n",
      "Fold 5 started at Sat May 25 13:42:30 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.32033\tvalid_1's rmse: 1.7699\n",
      "Early stopping, best iteration is:\n",
      "[1121]\ttraining's rmse: 1.2681\tvalid_1's rmse: 1.76443\n",
      "Fold 6 started at Sat May 25 13:42:33 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[796]\ttraining's rmse: 1.35889\tvalid_1's rmse: 2.24386\n",
      "Fold 7 started at Sat May 25 13:42:36 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.28199\tvalid_1's rmse: 2.16694\n",
      "Early stopping, best iteration is:\n",
      "[917]\ttraining's rmse: 1.31176\tvalid_1's rmse: 2.165\n",
      "Fold 8 started at Sat May 25 13:42:39 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[574]\ttraining's rmse: 1.47778\tvalid_1's rmse: 2.08103\n",
      "Fold 9 started at Sat May 25 13:42:41 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[237]\ttraining's rmse: 1.75908\tvalid_1's rmse: 2.00601\n",
      "CV mean score: 1.9638, std: 0.1605.\n"
     ]
    }
   ],
   "source": [
    "params = {'num_leaves': 30,\n",
    "         'min_data_in_leaf': 20,\n",
    "         'objective': 'regression',\n",
    "         'max_depth': 5,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.2,\n",
    "         \"verbosity\": -1}\n",
    "oof_lgb_1, prediction_lgb_1 = train_model(X, X_test, y, params=params, model_type='lgb', plot_feature_importance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sat May 25 13:43:50 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[395]\ttraining's rmse: 1.1989\tvalid_1's rmse: 1.98692\n",
      "Fold 1 started at Sat May 25 13:43:52 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[298]\ttraining's rmse: 1.30374\tvalid_1's rmse: 1.86352\n",
      "Fold 2 started at Sat May 25 13:43:53 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[427]\ttraining's rmse: 1.17528\tvalid_1's rmse: 1.8026\n",
      "Fold 3 started at Sat May 25 13:43:55 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[315]\ttraining's rmse: 1.30362\tvalid_1's rmse: 1.78202\n",
      "Fold 4 started at Sat May 25 13:43:56 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[639]\ttraining's rmse: 0.930049\tvalid_1's rmse: 2.00202\n",
      "Fold 5 started at Sat May 25 13:43:58 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[191]\ttraining's rmse: 1.50871\tvalid_1's rmse: 1.79864\n",
      "Fold 6 started at Sat May 25 13:43:59 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[224]\ttraining's rmse: 1.40931\tvalid_1's rmse: 2.27946\n",
      "Fold 7 started at Sat May 25 13:44:00 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[471]\ttraining's rmse: 1.09026\tvalid_1's rmse: 2.1114\n",
      "Fold 8 started at Sat May 25 13:44:02 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[309]\ttraining's rmse: 1.29954\tvalid_1's rmse: 2.08817\n",
      "Fold 9 started at Sat May 25 13:44:03 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's rmse: 1.6748\tvalid_1's rmse: 1.97616\n",
      "CV mean score: 1.9691, std: 0.1533.\n"
     ]
    }
   ],
   "source": [
    "params = {'num_leaves': 30,\n",
    "         'min_data_in_leaf': 20,\n",
    "         'objective': 'regression',\n",
    "         'max_depth': 7,\n",
    "         'learning_rate': 0.02,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.7,\n",
    "         \"bagging_freq\": 5,\n",
    "         \"bagging_fraction\": 0.7,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.2,\n",
    "         \"verbosity\": -1}\n",
    "oof_lgb_2, prediction_lgb_2 = train_model(X, X_test, y, params=params, model_type='lgb', plot_feature_importance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack = np.vstack([oof_lgb, oof_xgb, oof_cat, oof_lgb_1, oof_lgb_2]).transpose()\n",
    "train_stack = pd.DataFrame(train_stack, columns=['lgb', 'xgb', 'cat', 'lgb_1', 'lgb_2'])\n",
    "test_stack = np.vstack([prediction_lgb, prediction_xgb, prediction_cat, prediction_lgb_1, prediction_lgb_2]).transpose()\n",
    "test_stack = pd.DataFrame(test_stack, columns=['lgb', 'xgb', 'cat', 'lgb_1', 'lgb_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sat May 25 13:45:10 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[412]\ttraining's rmse: 1.86972\tvalid_1's rmse: 1.95979\n",
      "Fold 1 started at Sat May 25 13:45:10 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[267]\ttraining's rmse: 1.91782\tvalid_1's rmse: 1.82659\n",
      "Fold 2 started at Sat May 25 13:45:10 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[323]\ttraining's rmse: 1.91217\tvalid_1's rmse: 1.76362\n",
      "Fold 3 started at Sat May 25 13:45:10 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[320]\ttraining's rmse: 1.90529\tvalid_1's rmse: 1.80979\n",
      "Fold 4 started at Sat May 25 13:45:11 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[231]\ttraining's rmse: 1.9104\tvalid_1's rmse: 2.05256\n",
      "Fold 5 started at Sat May 25 13:45:11 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[433]\ttraining's rmse: 1.88299\tvalid_1's rmse: 1.75363\n",
      "Fold 6 started at Sat May 25 13:45:11 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1.78008\tvalid_1's rmse: 2.24515\n",
      "Early stopping, best iteration is:\n",
      "[807]\ttraining's rmse: 1.79261\tvalid_1's rmse: 2.24355\n",
      "Fold 7 started at Sat May 25 13:45:11 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[532]\ttraining's rmse: 1.84397\tvalid_1's rmse: 2.10679\n",
      "Fold 8 started at Sat May 25 13:45:12 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[534]\ttraining's rmse: 1.84419\tvalid_1's rmse: 2.0698\n",
      "Fold 9 started at Sat May 25 13:45:12 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[169]\ttraining's rmse: 1.95642\tvalid_1's rmse: 2.00798\n",
      "CV mean score: 1.9594, std: 0.1570.\n"
     ]
    }
   ],
   "source": [
    "params = {'num_leaves': 8,\n",
    "         'min_data_in_leaf': 20,\n",
    "         'objective': 'regression',\n",
    "         'max_depth': 3,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.2,\n",
    "         \"verbosity\": -1}\n",
    "oof_lgb_stack, prediction_lgb_stack, = train_model(train_stack, test_stack, y, params=params, model_type='lgb', plot_feature_importance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sat May 25 13:46:00 2019\n",
      "Fold 1 started at Sat May 25 13:46:00 2019\n",
      "Fold 2 started at Sat May 25 13:46:00 2019\n",
      "Fold 3 started at Sat May 25 13:46:01 2019\n",
      "Fold 4 started at Sat May 25 13:46:01 2019\n",
      "Fold 5 started at Sat May 25 13:46:01 2019\n",
      "Fold 6 started at Sat May 25 13:46:01 2019\n",
      "Fold 7 started at Sat May 25 13:46:01 2019\n",
      "Fold 8 started at Sat May 25 13:46:01 2019\n",
      "Fold 9 started at Sat May 25 13:46:01 2019\n",
      "CV mean score: 1.9404, std: 0.1716.\n"
     ]
    }
   ],
   "source": [
    "model = RidgeCV(alphas=(0.01, 0.1, 1.0, 10.0, 100.0), scoring='neg_mean_squared_error', cv=folds)\n",
    "oof_rcv_stack, prediction_rcv_stack = train_model(train_stack.values, test_stack.values, y, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('data/sample_submission.csv')\n",
    "sub['revenue'] = np.expm1(prediction_lgb)\n",
    "sub.to_csv(\"lgb.csv\", index=False)\n",
    "sub['revenue'] = np.expm1((prediction_lgb + prediction_xgb) / 2)\n",
    "sub.to_csv(\"blend.csv\", index=False)\n",
    "sub['revenue'] = np.expm1((prediction_lgb + prediction_xgb + prediction_cat) / 3)\n",
    "sub.to_csv(\"blend1.csv\", index=False)\n",
    "sub['revenue'] = np.expm1((prediction_lgb + prediction_xgb + prediction_cat + prediction_lgb_1) / 4)\n",
    "sub.to_csv(\"blend2.csv\", index=False)\n",
    "sub['revenue'] = np.expm1((prediction_lgb + prediction_xgb + prediction_cat + prediction_lgb_1 + prediction_lgb_2) / 5)\n",
    "sub.to_csv(\"blend3.csv\", index=False)\n",
    "\n",
    "sub['revenue'] = prediction_lgb_stack\n",
    "sub.to_csv(\"stack_lgb.csv\", index=False)\n",
    "sub['revenue'] = prediction_rcv_stack\n",
    "sub.to_csv(\"stack_rcv.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend = pd.read_csv('blend3.csv')\n",
    "ens = pd.read_csv('submission_ens.csv.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_sub = (blend['revenue'] + ens['revenue']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('data/sample_submission.csv')\n",
    "sub['revenue'] = extend_sub\n",
    "sub.to_csv(\"new_extend_sub.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
